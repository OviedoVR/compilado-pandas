[
  {
    "objectID": "sections/visualizacao.html",
    "href": "sections/visualizacao.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesta aula, vamos trabalhar com métodos aplicáveis à limpeza de dados com Pandas. Veremos :\n\nMétodos de plotagem built-in do Pandas\nUm exemplo usando seaborn\nComo aplicar estilos em dataframes.\n\nPara isso, trabalharemos no conjunto de dados da última aula (pós-limpeza).\n\nimport pandas as pd\n\nclientes_cifraonline = pd.read_csv('dados/clientes-banco-cifraonline/clientes_cifraonline_limpo.csv')\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\ngenero_cod\nsalario_anual\ngenero_cod_lambda\nfaixa_score\n\n\n\n\n0\nMariano\n65\nM\n7000.0\nPorto Alegre\nAutônomo\nPós-graduação\n626\n1\n84000.0\n1\nMédio\n\n\n1\nLuiz\n71\nM\n6545.0\nRio de Janeiro\nAutônomo\nGraduação\n438\n1\n78540.0\n1\nBaixo\n\n\n2\nCarlo\n21\nM\n12383.0\nSalvador\nAutônomo\nGraduação\n384\n1\n148596.0\n1\nBaixo\n\n\n3\nLuiz\n77\nM\n1823.0\nPorto Alegre\nAutônomo\nEnsino Médio\n737\n1\n21876.0\n1\nAlto\n\n\n4\nFelipe\n21\nM\n1490.0\nPorto Alegre\nAutônomo\nEnsino Médio\n482\n1\n17880.0\n1\nBaixo\n\n\n\n\n\n\n\n\n\n\nScatter plot\n\npd.options.plotting.backend = 'matplotlib'\nclientes_cifraonline.plot.scatter(x='idade', y='salario')\n\n\n\nGráfico de dispersão\n\n\n\nGráfico de barras:\n\npd.options.plotting.backend = 'matplotlib'\nclientes_cifraonline[['score_credito']].head(10).plot.barh(color='k',)\n\n\n\nGráfico de barras\n\n\n\nBoxplot\n\npd.options.plotting.backend = 'matplotlib'\nclientes_cifraonline['score_credito'].plot.box()\n\n\n\nGráfico de boxplot\n\n\nAdicionalmente, podemos mudar a biblioteca por trás das plotagens. Seguem algumas opções:\npd.options.plotting.backend = 'matplotlib'    # (default)\npd.options.plotting.backend = 'plotly'\npd.options.plotting.backend = 'pandas_bokeh'\npd.options.plotting.backend = 'hvplot'\nPor exemplo, a biblioteca plotly é muito interessante nesses casos, pois traz interatividade ao gráfico.\n\n# Desconsiderar este código (apenas ajuste de layout):\nimport plotly.io as pio\n\n# Defina as configurações padrão para os gráficos\nlayout_defaults = dict(\n    plot_bgcolor='rgb(28, 31, 43)',\n    paper_bgcolor='rgb(28, 31, 43)',\n    legend=dict(font=dict(color=\"white\")),\n    xaxis=dict(tickfont=dict(color=\"white\"), gridcolor=\"white\", linecolor=\"white\"),\n    yaxis=dict(tickfont=dict(color=\"white\"), gridcolor=\"white\", linecolor=\"white\"),\n    colorway=[\"white\"]\n)\n\n\nHistograma com plotly\n\n\npd.options.plotting.backend = 'plotly'\n\nhistograma = clientes_cifraonline['score_credito'].plot.hist(template='simple_white', width=420, height=300)\nhistograma.update_layout(layout_defaults)\nhistograma.show()\n\n                                                \n\n\n\nBoxplot com plotly\n\n\npd.options.plotting.backend = 'plotly'\nboxplot = clientes_cifraonline['score_credito'].plot.box(template='simple_white', width=350, height=300)\nboxplot.update_layout(layout_defaults)\nboxplot.show()\n\n                                                \n\n\n\n\n\nO Python conta com inúmeras bibliotecas de visualização. Alguns exemplos são:\n\nMatplotlib\nSeaborn (baseada em matplotlib)\nPlotly\nBokeh\n\nNesta seção vamos ver um exemplo em seaborn, com um toque de sotrytelling. Suponha o bloco de código e a respectiva saída a seguir. Nele temos um gráfico stripplot para o score de crédito dos clientes (cada ponto é um cliente).\n# bibliotecas:\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# gráfico de stripplot:\nfig, ax = plt.subplots()\nsns.stripplot(\n    data=clientes_cifraonline, \n    y='score_credito', \n    color='lightgray', \n    size=7, alpha=0.7, jitter=0.25, \n    label='cliente'\n)\n# layout\nplt.xticks([]);\nplt.legend(loc='lower left')\nplt.ylabel('Score');\nplt.title('Score de crétido dos clientes ', weight='bold', loc='left');\n\n\n\nStripplot gerado com Seaborn\n\n\nVamos supor que se deseja responder à seguinte pergunta:\n\nQuantos clientes tem o score de crédito acima de 700?\n\nSe deseja responder essa pergunta, pois esses clientes com score maior ou igual a 700 têm um perfil muito interessante para o négocio. Todavia, como podemos comunicar isso de maneira bem visual? Abaixo, temos um singelo exemplo.\n# Regra de negócio:\nclientes_cifraonline['performance_score'] = clientes_cifraonline['score_credito'].apply(\n    lambda score: 'Sim' if score &gt;= 700 else 'Não'\n)\n\n# Contagem de clientes com score maior ou igual a 700: \ncontagem_clientes = len(clientes_cifraonline.query('performance_score == \"Sim\" '))\npercentual = round(contagem_clientes / len(clientes_cifraonline) * 100, 2)\n\n# Visualização de dados:\nfig, ax = plt.subplots()\nsns.stripplot(\n    data=clientes_cifraonline, y='score_credito', \n     hue='performance_score', \n     palette=['royalblue', 'lightgray'], \n     size=7.5, alpha=0.7, jitter=0.25\n)\nplt.axhline(\n    y=700, lw=1, ls='--', \n    color='royalblue',\n    label='Score 700'\n)\nplt.title(f'Aproximadamente ({percentual}%) dos clientes têm score acima de 700', \n    weight='bold', color='royalblue', loc='left', size=10\n);\nplt.legend().remove();\n\n\n\nExemplo: visualização de dados\n\n\n\n\n\nclientes_cifraonline.head().style.format(precision=2)\\\n    .background_gradient()\n\n\n\nEstilos: gradiente\n\n\nclientes_cifraonline.head().style.format(precision=2)\\\n    .bar(color='chartreuse')\n\n\n\nEstilos: barras\n\n\nclientes_cifraonline.head().style.format(precision=2)\\\n    .bar(subset='salario', color='chartreuse')\n\n\n\nEstilos: destacar entrebarras (coluna específica)\n\n\nclientes_cifraonline.head().style.format(precision=2)\\\n    .highlight_between(subset='idade', left=60, right=75, color='orange')\n\n\n\nEstilos: destacar entre X-Y\n\n\n# Criando uma função definida:\ndef estilizar_dataframe(style):\n    style.format(precision=2).bar(subset='salario', color='chartreuse')\n    style.format(precision=2).background_gradient(subset='idade')\n    return style\n\n# Aplicação:\nclientes_cifraonline.head().style.pipe(estilizar_dataframe)\n\n\n\nEstilos: definido por uma função"
  },
  {
    "objectID": "sections/visualizacao.html#métodos-built-in",
    "href": "sections/visualizacao.html#métodos-built-in",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Scatter plot\n\npd.options.plotting.backend = 'matplotlib'\nclientes_cifraonline.plot.scatter(x='idade', y='salario')\n\n\n\nGráfico de dispersão\n\n\n\nGráfico de barras:\n\npd.options.plotting.backend = 'matplotlib'\nclientes_cifraonline[['score_credito']].head(10).plot.barh(color='k',)\n\n\n\nGráfico de barras\n\n\n\nBoxplot\n\npd.options.plotting.backend = 'matplotlib'\nclientes_cifraonline['score_credito'].plot.box()\n\n\n\nGráfico de boxplot\n\n\nAdicionalmente, podemos mudar a biblioteca por trás das plotagens. Seguem algumas opções:\npd.options.plotting.backend = 'matplotlib'    # (default)\npd.options.plotting.backend = 'plotly'\npd.options.plotting.backend = 'pandas_bokeh'\npd.options.plotting.backend = 'hvplot'\nPor exemplo, a biblioteca plotly é muito interessante nesses casos, pois traz interatividade ao gráfico.\n\n# Desconsiderar este código (apenas ajuste de layout):\nimport plotly.io as pio\n\n# Defina as configurações padrão para os gráficos\nlayout_defaults = dict(\n    plot_bgcolor='rgb(28, 31, 43)',\n    paper_bgcolor='rgb(28, 31, 43)',\n    legend=dict(font=dict(color=\"white\")),\n    xaxis=dict(tickfont=dict(color=\"white\"), gridcolor=\"white\", linecolor=\"white\"),\n    yaxis=dict(tickfont=dict(color=\"white\"), gridcolor=\"white\", linecolor=\"white\"),\n    colorway=[\"white\"]\n)\n\n\nHistograma com plotly\n\n\npd.options.plotting.backend = 'plotly'\n\nhistograma = clientes_cifraonline['score_credito'].plot.hist(template='simple_white', width=420, height=300)\nhistograma.update_layout(layout_defaults)\nhistograma.show()\n\n                                                \n\n\n\nBoxplot com plotly\n\n\npd.options.plotting.backend = 'plotly'\nboxplot = clientes_cifraonline['score_credito'].plot.box(template='simple_white', width=350, height=300)\nboxplot.update_layout(layout_defaults)\nboxplot.show()"
  },
  {
    "objectID": "sections/visualizacao.html#bibliotecas-de-visualização",
    "href": "sections/visualizacao.html#bibliotecas-de-visualização",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "O Python conta com inúmeras bibliotecas de visualização. Alguns exemplos são:\n\nMatplotlib\nSeaborn (baseada em matplotlib)\nPlotly\nBokeh\n\nNesta seção vamos ver um exemplo em seaborn, com um toque de sotrytelling. Suponha o bloco de código e a respectiva saída a seguir. Nele temos um gráfico stripplot para o score de crédito dos clientes (cada ponto é um cliente).\n# bibliotecas:\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# gráfico de stripplot:\nfig, ax = plt.subplots()\nsns.stripplot(\n    data=clientes_cifraonline, \n    y='score_credito', \n    color='lightgray', \n    size=7, alpha=0.7, jitter=0.25, \n    label='cliente'\n)\n# layout\nplt.xticks([]);\nplt.legend(loc='lower left')\nplt.ylabel('Score');\nplt.title('Score de crétido dos clientes ', weight='bold', loc='left');\n\n\n\nStripplot gerado com Seaborn\n\n\nVamos supor que se deseja responder à seguinte pergunta:\n\nQuantos clientes tem o score de crédito acima de 700?\n\nSe deseja responder essa pergunta, pois esses clientes com score maior ou igual a 700 têm um perfil muito interessante para o négocio. Todavia, como podemos comunicar isso de maneira bem visual? Abaixo, temos um singelo exemplo.\n# Regra de negócio:\nclientes_cifraonline['performance_score'] = clientes_cifraonline['score_credito'].apply(\n    lambda score: 'Sim' if score &gt;= 700 else 'Não'\n)\n\n# Contagem de clientes com score maior ou igual a 700: \ncontagem_clientes = len(clientes_cifraonline.query('performance_score == \"Sim\" '))\npercentual = round(contagem_clientes / len(clientes_cifraonline) * 100, 2)\n\n# Visualização de dados:\nfig, ax = plt.subplots()\nsns.stripplot(\n    data=clientes_cifraonline, y='score_credito', \n     hue='performance_score', \n     palette=['royalblue', 'lightgray'], \n     size=7.5, alpha=0.7, jitter=0.25\n)\nplt.axhline(\n    y=700, lw=1, ls='--', \n    color='royalblue',\n    label='Score 700'\n)\nplt.title(f'Aproximadamente ({percentual}%) dos clientes têm score acima de 700', \n    weight='bold', color='royalblue', loc='left', size=10\n);\nplt.legend().remove();\n\n\n\nExemplo: visualização de dados"
  },
  {
    "objectID": "sections/visualizacao.html#estilos",
    "href": "sections/visualizacao.html#estilos",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "clientes_cifraonline.head().style.format(precision=2)\\\n    .background_gradient()\n\n\n\nEstilos: gradiente\n\n\nclientes_cifraonline.head().style.format(precision=2)\\\n    .bar(color='chartreuse')\n\n\n\nEstilos: barras\n\n\nclientes_cifraonline.head().style.format(precision=2)\\\n    .bar(subset='salario', color='chartreuse')\n\n\n\nEstilos: destacar entrebarras (coluna específica)\n\n\nclientes_cifraonline.head().style.format(precision=2)\\\n    .highlight_between(subset='idade', left=60, right=75, color='orange')\n\n\n\nEstilos: destacar entre X-Y\n\n\n# Criando uma função definida:\ndef estilizar_dataframe(style):\n    style.format(precision=2).bar(subset='salario', color='chartreuse')\n    style.format(precision=2).background_gradient(subset='idade')\n    return style\n\n# Aplicação:\nclientes_cifraonline.head().style.pipe(estilizar_dataframe)\n\n\n\nEstilos: definido por uma função"
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html",
    "href": "sections/metodos_basicos_pandas.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesta aula, vamos trabalhar com um conjunto de dados sobre vendas. Veremos métodos para:\n\nMostrar as N primeiras ou N últimas linhas\nVerificar o tamanho do dataframe\nVerificar os tipos de dados (variáveis) e informaçoes gerais\nInspecionar a presença de dados nulos/ausentes\nInvestigar valores disintos\nRealizar contagem de valores\nListar duplicatas\nCriar novas colunas.\n\nEntretanto, vamos carregar os dados a partir do bloco de código abaixo:\n\nimport pandas as pd\n\nvendas_europa = pd.read_csv('dados/vendas/EuropeSalesRecords.csv')\nvendas_europa\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n634033286\n1/15/2014\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n559183347\n5/21/2014\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n781416594\n12/23/2015\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n1330 rows × 14 columns\n\n\n\nDito isso, nada melhor que o velho “hands-on”.\n\n\n\n# Dafault: N=5\nvendas_europa.head()\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n\n\n\n\n\n\n# É possível selecionar o numero de linhas a mostrar:\nvendas_europa.head(2)\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n\n\n\n\n\n\nÚltimas cinco linhas:\n\n\nvendas_europa.tail()\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n634033286\n1/15/2014\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n559183347\n5/21/2014\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n781416594\n12/23/2015\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n\n\n\n\nvendas_europa.tail(2)\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n\n\n\n\n\n\nPodemos verificar utilizando o método .shape. Isso retorna uma tupla de dois números: (linhas, colunas).\n\nvendas_europa.shape\n\n(1330, 14)\n\n\n\nUma maneira mais organizada\n\n\nlinhas, colunas = vendas_europa.shape\nprint(f'Linhas: {linhas}, Colunas: {colunas}')\n\nLinhas: 1330, Colunas: 14\n\n\n\n\n\nCom o método .info() podemos verificar o tipo de dado em cada coluna, o número total de linhas e colunas, o total de nulos e não-nulos no conjunto de dados, além do espaço ocupado em memória.\n\nvendas_europa.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1330 entries, 0 to 1329\nData columns (total 14 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   Region          1330 non-null   object \n 1   Country         1330 non-null   object \n 2   Item Type       1330 non-null   object \n 3   Sales Channel   1330 non-null   object \n 4   Order Priority  1324 non-null   object \n 5   Order Date      1330 non-null   object \n 6   Order ID        1330 non-null   int64  \n 7   Ship Date       1330 non-null   object \n 8   Units Sold      1330 non-null   int64  \n 9   Unit Price      1330 non-null   float64\n 10  Unit Cost       1330 non-null   float64\n 11  Total Revenue   1330 non-null   float64\n 12  Total Cost      1330 non-null   float64\n 13  Total Profit    1330 non-null   float64\ndtypes: float64(5), int64(2), object(7)\nmemory usage: 145.6+ KB\n\n\nÉ possível ainda listar as colunas do dataframe.\n\nvendas_europa.columns\n\nIndex(['Region', 'Country', 'Item Type', 'Sales Channel', 'Order Priority',\n       'Order Date', 'Order ID', 'Ship Date', 'Units Sold', 'Unit Price',\n       'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit'],\n      dtype='object')\n\n\n\n\n\nA partir do método .insna() podemos verificar a presença de nulos, mostrar a contagem de nulos, bem como o percentual de nulos no conjunto de dados. Vejamos a seguir:\n\nTotal de nulos:\n\n\nvendas_europa.isna().sum()\n\nRegion            0\nCountry           0\nItem Type         0\nSales Channel     0\nOrder Priority    6\nOrder Date        0\nOrder ID          0\nShip Date         0\nUnits Sold        0\nUnit Price        0\nUnit Cost         0\nTotal Revenue     0\nTotal Cost        0\nTotal Profit      0\ndtype: int64\n\n\n\nPercentual de nulos:\n\n\nvendas_europa.isna().sum() / len(vendas_europa) * 100\n\nRegion            0.000000\nCountry           0.000000\nItem Type         0.000000\nSales Channel     0.000000\nOrder Priority    0.451128\nOrder Date        0.000000\nOrder ID          0.000000\nShip Date         0.000000\nUnits Sold        0.000000\nUnit Price        0.000000\nUnit Cost         0.000000\nTotal Revenue     0.000000\nTotal Cost        0.000000\nTotal Profit      0.000000\ndtype: float64\n\n\nNote que temos 0,45% de dados nulos na coluna Order Priority, correspondente a 6 valores.\n\n\n\nA partir do método .unique() podemos verificar os valores distintos em determinada coluna do conjunto de dados. Consideremos a coluna Item Type, podemos verificar os valores distintos dessa coluna por meio do seguinte código:\n\nvendas_europa['Item Type'].unique()\n\narray(['Beverages', 'Clothes', 'Cereal', 'Office Supplies', 'Fruits',\n       'Vegetables', 'Meat', 'Snacks', 'Baby Food', 'Household',\n       'Cosmetics', 'Personal Care'], dtype=object)\n\n\nAnalogamente, podemos mostrar quantas categorias temos em Item Type utilizando o método .nunique().\n\nvendas_europa['Item Type'].nunique()\n\n12\n\n\n\n\n\nA partir do método .value_counts() podemos realizar a contagem em determinada coluna do conjunto de dados. Consideremos a coluna Item Type, podemos verificar quais valores distintos temos por meio do seguinte código:\n\nvendas_europa['Item Type'].value_counts()\n\nItem Type\nOffice Supplies    123\nBeverages          121\nPersonal Care      115\nVegetables         114\nCosmetics          114\nFruits             112\nBaby Food          112\nMeat               111\nClothes            105\nCereal             103\nSnacks             103\nHousehold           97\nName: count, dtype: int64\n\n\nSe optarmos por incluir os dados nulos, podemos utilizar a opção dropna=False.\n\nvendas_europa['Order Priority'].value_counts(dropna=False)\n\nOrder Priority\nM      352\nL      334\nH      334\nC      304\nNaN      6\nName: count, dtype: int64\n\n\n\n\n\nPodemos inclusive plotar essa contagem, mas isso veremos com mais calma adiante.\n\n\nvendas_europa['Item Type'].value_counts().plot.barh(color='k', figsize=(6,4))\n\n\n\n\n\n\n\n\n\n\n\n\nSabemos que a coluna Sales Channel vai ter várias duplicatas (pois só poucas opções de valores para o canal de vendas). Logo vamos listar quais são os valores que contém duplicatas.\n\nvendas_europa['Sales Channel'].drop_duplicates()\n\n0    Offline\n1     Online\nName: Sales Channel, dtype: object\n\n\nAlternativamente, podemos listar um subset e listar duplicatas em relação a ele:\n\nvendas_europa.drop_duplicates(subset=['Country'])\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n5\nEurope\nMontenegro\nFruits\nOffline\nL\n5/29/2016\n313705861\n7/10/2016\n1390\n9.33\n6.92\n12968.70\n9618.80\n3349.90\n\n\n7\nEurope\nLuxembourg\nVegetables\nOffline\nL\n2/13/2010\n744683635\n4/1/2010\n7291\n154.06\n90.93\n1123251.46\n662970.63\n460280.83\n\n\n8\nEurope\nSwitzerland\nMeat\nOnline\nL\n3/21/2014\n169378983\n4/10/2014\n1860\n421.89\n364.69\n784715.40\n678323.40\n106392.00\n\n\n9\nEurope\nFinland\nBeverages\nOnline\nH\n3/16/2012\n566428315\n3/23/2012\n7581\n47.45\n31.79\n359718.45\n240999.99\n118718.46\n\n\n10\nEurope\nBelgium\nSnacks\nOnline\nM\n1/12/2015\n519380223\n1/17/2015\n5005\n152.58\n97.44\n763662.90\n487687.20\n275975.70\n\n\n11\nEurope\nSan Marino\nOffice Supplies\nOnline\nH\n4/13/2014\n904589211\n5/4/2014\n6905\n651.21\n524.96\n4496605.05\n3624848.80\n871756.25\n\n\n13\nEurope\nNetherlands\nMeat\nOffline\nM\n3/8/2017\n747774398\n4/3/2017\n1916\n421.89\n364.69\n808341.24\n698746.04\n109595.20\n\n\n14\nEurope\nRussia\nHousehold\nOnline\nM\n7/10/2017\n194176757\n8/20/2017\n72\n668.27\n502.54\n48115.44\n36182.88\n11932.56\n\n\n15\nEurope\nUkraine\nCosmetics\nOnline\nH\n1/22/2011\n773645913\n1/28/2011\n7873\n437.20\n263.33\n3442075.60\n2073197.09\n1368878.51\n\n\n17\nEurope\nLatvia\nMeat\nOffline\nM\n12/15/2011\n847317397\n12/18/2011\n8902\n421.89\n364.69\n3755664.78\n3246470.38\n509194.40\n\n\n18\nEurope\nSerbia\nBeverages\nOnline\nL\n9/3/2012\n599624192\n9/21/2012\n978\n47.45\n31.79\n46406.10\n31090.62\n15315.48\n\n\n19\nEurope\nPortugal\nOffice Supplies\nOnline\nM\n1/21/2014\n734318292\n3/4/2014\n9956\n651.21\n524.96\n6483446.76\n5226501.76\n1256945.00\n\n\n20\nEurope\nPoland\nHousehold\nOffline\nL\n7/7/2017\n232196319\n8/4/2017\n905\n668.27\n502.54\n604784.35\n454798.70\n149985.65\n\n\n21\nEurope\nLiechtenstein\nCosmetics\nOnline\nL\n7/15/2012\n229693067\n7/15/2012\n138\n437.20\n263.33\n60333.60\n36339.54\n23994.06\n\n\n22\nEurope\nUnited Kingdom\nBeverages\nOnline\nC\n4/8/2017\n121945512\n4/12/2017\n5242\n47.45\n31.79\n248732.90\n166643.18\n82089.72\n\n\n23\nEurope\nSlovenia\nFruits\nOnline\nH\n10/22/2012\n169799983\n11/20/2012\n6443\n9.33\n6.92\n60113.19\n44585.56\n15527.63\n\n\n24\nEurope\nMalta\nVegetables\nOnline\nM\n3/11/2014\n894589078\n4/10/2014\n7643\n154.06\n90.93\n1177480.58\n694977.99\n482502.59\n\n\n26\nEurope\nCyprus\nFruits\nOffline\nM\n7/12/2015\n600515115\n8/30/2015\n4622\n9.33\n6.92\n43123.26\n31984.24\n11139.02\n\n\n28\nEurope\nMonaco\nPersonal Care\nOnline\nL\n6/8/2014\n263098371\n7/4/2014\n5509\n81.73\n56.67\n450250.57\n312195.03\n138055.54\n\n\n30\nEurope\nNorway\nCereal\nOnline\nM\n10/8/2014\n100640618\n10/18/2014\n650\n205.70\n117.11\n133705.00\n76121.50\n57583.50\n\n\n33\nEurope\nArmenia\nFruits\nOnline\nM\n3/23/2011\n120977771\n5/2/2011\n8866\n9.33\n6.92\n82719.78\n61352.72\n21367.06\n\n\n35\nEurope\nDenmark\nBeverages\nOnline\nH\n6/5/2016\n973268353\n6/26/2016\n589\n47.45\n31.79\n27948.05\n18724.31\n9223.74\n\n\n37\nEurope\nKosovo\nFruits\nOnline\nL\n5/2/2010\n291995418\n6/6/2010\n6788\n9.33\n6.92\n63332.04\n46972.96\n16359.08\n\n\n38\nEurope\nHungary\nBaby Food\nOnline\nM\n1/25/2011\n128686225\n3/13/2011\n9968\n255.28\n159.42\n2544631.04\n1589098.56\n955532.48\n\n\n39\nEurope\nLithuania\nCosmetics\nOffline\nL\n1/6/2012\n420875346\n2/18/2012\n5223\n437.20\n263.33\n2283495.60\n1375372.59\n908123.01\n\n\n40\nEurope\nAlbania\nVegetables\nOnline\nC\n10/5/2012\n476633536\n11/3/2012\n5310\n154.06\n90.93\n818058.60\n482838.30\n335220.30\n\n\n42\nEurope\nMoldova\nPersonal Care\nOnline\nM\n3/11/2013\n467045819\n4/12/2013\n8092\n81.73\n56.67\n661359.16\n458573.64\n202785.52\n\n\n51\nEurope\nFrance\nMeat\nOnline\nL\n11/28/2015\n245440852\n12/17/2015\n257\n421.89\n364.69\n108425.73\n93725.33\n14700.40\n\n\n52\nEurope\nSpain\nFruits\nOnline\nH\n10/22/2011\n817006289\n11/14/2011\n9172\n9.33\n6.92\n85574.76\n63470.24\n22104.52\n\n\n53\nEurope\nSweden\nVegetables\nOnline\nH\n9/20/2010\n298228013\n10/25/2010\n1151\n154.06\n90.93\n177323.06\n104660.43\n72662.63\n\n\n59\nEurope\nMacedonia\nCosmetics\nOnline\nC\n12/26/2010\n350977408\n1/22/2011\n869\n437.20\n263.33\n379926.80\n228833.77\n151093.03\n\n\n60\nEurope\nGreece\nPersonal Care\nOffline\nNaN\n12/8/2011\n701298367\n1/6/2012\n8626\n81.73\n56.67\n705002.98\n488835.42\n216167.56\n\n\n61\nEurope\nItaly\nPersonal Care\nOnline\nC\n2/25/2011\n309342658\n3/28/2011\n222\n81.73\n56.67\n18144.06\n12580.74\n5563.32\n\n\n66\nEurope\nGermany\nBaby Food\nOffline\nL\n1/6/2017\n361311852\n2/15/2017\n9061\n255.28\n159.42\n2313092.08\n1444504.62\n868587.46\n\n\n78\nEurope\nAndorra\nCereal\nOnline\nH\n3/19/2010\n696197879\n3/26/2010\n9278\n205.70\n117.11\n1908484.60\n1086546.58\n821938.02\n\n\n79\nEurope\nIceland\nCosmetics\nOnline\nC\n4/5/2012\n907349526\n5/16/2012\n3743\n437.20\n263.33\n1636439.60\n985644.19\n650795.41\n\n\n83\nEurope\nCroatia\nBeverages\nOffline\nL\n2/22/2013\n189924275\n3/21/2013\n1668\n47.45\n31.79\n79146.60\n53025.72\n26120.88\n\n\n89\nEurope\nSlovakia\nHousehold\nOffline\nL\n2/20/2010\n585362994\n4/11/2010\n773\n668.27\n502.54\n516572.71\n388463.42\n128109.29\n\n\n96\nEurope\nVatican City\nBeverages\nOnline\nC\n12/27/2015\n370484149\n1/19/2016\n3348\n47.45\n31.79\n158862.60\n106432.92\n52429.68\n\n\n99\nEurope\nBelarus\nVegetables\nOnline\nL\n12/31/2012\n413078916\n1/11/2013\n8086\n154.06\n90.93\n1245729.16\n735259.98\n510469.18\n\n\n102\nEurope\nIreland\nVegetables\nOffline\nC\n11/16/2010\n901670968\n12/11/2010\n3331\n154.06\n90.93\n513173.86\n302887.83\n210286.03\n\n\n140\nEurope\nRomania\nSnacks\nOnline\nH\n8/18/2014\n747327220\n9/15/2014\n9587\n152.58\n97.44\n1462784.46\n934157.28\n528627.18\n\n\n152\nEurope\nGeorgia\nBaby Food\nOnline\nL\n1/26/2014\n359197413\n3/8/2014\n3352\n255.28\n159.42\n855698.56\n534375.84\n321322.72\n\n\n\n\n\n\n\nNote que retornou apenas países que contém duplicatas.\n\n\n\nPodemos também criar novas colunas. Vamos supor que se deseja obter os valores de Total Profit em real brasileiro (BRL ou R$) ao invés de dólar (USD). Considerando 1 BRL = 4,96 USD (16/02/2024, 12h50). Tem-se:\n\n# Transformando Total Profit em inteiro:\nvendas_europa['Total Profit'] = vendas_europa['Total Profit'].astype('int') \n\n# Convertendo USD para BRL:\nvendas_europa['Total Profit (BRL)'] = vendas_europa['Total Profit'] * 4.96\n\n# Visualizando o resultado:\nvendas_europa[['Total Profit (BRL)', 'Total Profit']].head()\n\n\n\n\n\n\n\n\nTotal Profit (BRL)\nTotal Profit\n\n\n\n\n0\n371122.08\n74823\n\n\n1\n337666.88\n68078\n\n\n2\n2467704.16\n497521\n\n\n3\n3923766.72\n791082\n\n\n4\n59262.08\n11948\n\n\n\n\n\n\n\nOutro exemplo seria:\n\n# Marcando a versão:\nvendas_europa['Version'] = '001'\n\n# Resultado:\nvendas_europa[['Total Profit (BRL)', 'Total Profit', 'Version']].head()\n\n\n\n\n\n\n\n\nTotal Profit (BRL)\nTotal Profit\nVersion\n\n\n\n\n0\n371122.08\n74823\n001\n\n\n1\n337666.88\n68078\n001\n\n\n2\n2467704.16\n497521\n001\n\n\n3\n3923766.72\n791082\n001\n\n\n4\n59262.08\n11948\n001"
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#primeirasúltimas-n-linhas",
    "href": "sections/metodos_basicos_pandas.html#primeirasúltimas-n-linhas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "# Dafault: N=5\nvendas_europa.head()\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n\n\n\n\n\n\n# É possível selecionar o numero de linhas a mostrar:\nvendas_europa.head(2)\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n\n\n\n\n\n\nÚltimas cinco linhas:\n\n\nvendas_europa.tail()\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n634033286\n1/15/2014\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n559183347\n5/21/2014\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n781416594\n12/23/2015\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n\n\n\n\nvendas_europa.tail(2)\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40"
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#tamanho-do-dataframe",
    "href": "sections/metodos_basicos_pandas.html#tamanho-do-dataframe",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Podemos verificar utilizando o método .shape. Isso retorna uma tupla de dois números: (linhas, colunas).\n\nvendas_europa.shape\n\n(1330, 14)\n\n\n\nUma maneira mais organizada\n\n\nlinhas, colunas = vendas_europa.shape\nprint(f'Linhas: {linhas}, Colunas: {colunas}')\n\nLinhas: 1330, Colunas: 14"
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#tipo-de-dados-e-informações-gerais",
    "href": "sections/metodos_basicos_pandas.html#tipo-de-dados-e-informações-gerais",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Com o método .info() podemos verificar o tipo de dado em cada coluna, o número total de linhas e colunas, o total de nulos e não-nulos no conjunto de dados, além do espaço ocupado em memória.\n\nvendas_europa.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1330 entries, 0 to 1329\nData columns (total 14 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   Region          1330 non-null   object \n 1   Country         1330 non-null   object \n 2   Item Type       1330 non-null   object \n 3   Sales Channel   1330 non-null   object \n 4   Order Priority  1324 non-null   object \n 5   Order Date      1330 non-null   object \n 6   Order ID        1330 non-null   int64  \n 7   Ship Date       1330 non-null   object \n 8   Units Sold      1330 non-null   int64  \n 9   Unit Price      1330 non-null   float64\n 10  Unit Cost       1330 non-null   float64\n 11  Total Revenue   1330 non-null   float64\n 12  Total Cost      1330 non-null   float64\n 13  Total Profit    1330 non-null   float64\ndtypes: float64(5), int64(2), object(7)\nmemory usage: 145.6+ KB\n\n\nÉ possível ainda listar as colunas do dataframe.\n\nvendas_europa.columns\n\nIndex(['Region', 'Country', 'Item Type', 'Sales Channel', 'Order Priority',\n       'Order Date', 'Order ID', 'Ship Date', 'Units Sold', 'Unit Price',\n       'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit'],\n      dtype='object')"
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#dados-nulos",
    "href": "sections/metodos_basicos_pandas.html#dados-nulos",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "A partir do método .insna() podemos verificar a presença de nulos, mostrar a contagem de nulos, bem como o percentual de nulos no conjunto de dados. Vejamos a seguir:\n\nTotal de nulos:\n\n\nvendas_europa.isna().sum()\n\nRegion            0\nCountry           0\nItem Type         0\nSales Channel     0\nOrder Priority    6\nOrder Date        0\nOrder ID          0\nShip Date         0\nUnits Sold        0\nUnit Price        0\nUnit Cost         0\nTotal Revenue     0\nTotal Cost        0\nTotal Profit      0\ndtype: int64\n\n\n\nPercentual de nulos:\n\n\nvendas_europa.isna().sum() / len(vendas_europa) * 100\n\nRegion            0.000000\nCountry           0.000000\nItem Type         0.000000\nSales Channel     0.000000\nOrder Priority    0.451128\nOrder Date        0.000000\nOrder ID          0.000000\nShip Date         0.000000\nUnits Sold        0.000000\nUnit Price        0.000000\nUnit Cost         0.000000\nTotal Revenue     0.000000\nTotal Cost        0.000000\nTotal Profit      0.000000\ndtype: float64\n\n\nNote que temos 0,45% de dados nulos na coluna Order Priority, correspondente a 6 valores."
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#valores-disintos",
    "href": "sections/metodos_basicos_pandas.html#valores-disintos",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "A partir do método .unique() podemos verificar os valores distintos em determinada coluna do conjunto de dados. Consideremos a coluna Item Type, podemos verificar os valores distintos dessa coluna por meio do seguinte código:\n\nvendas_europa['Item Type'].unique()\n\narray(['Beverages', 'Clothes', 'Cereal', 'Office Supplies', 'Fruits',\n       'Vegetables', 'Meat', 'Snacks', 'Baby Food', 'Household',\n       'Cosmetics', 'Personal Care'], dtype=object)\n\n\nAnalogamente, podemos mostrar quantas categorias temos em Item Type utilizando o método .nunique().\n\nvendas_europa['Item Type'].nunique()\n\n12"
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#contagem-de-valores",
    "href": "sections/metodos_basicos_pandas.html#contagem-de-valores",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "A partir do método .value_counts() podemos realizar a contagem em determinada coluna do conjunto de dados. Consideremos a coluna Item Type, podemos verificar quais valores distintos temos por meio do seguinte código:\n\nvendas_europa['Item Type'].value_counts()\n\nItem Type\nOffice Supplies    123\nBeverages          121\nPersonal Care      115\nVegetables         114\nCosmetics          114\nFruits             112\nBaby Food          112\nMeat               111\nClothes            105\nCereal             103\nSnacks             103\nHousehold           97\nName: count, dtype: int64\n\n\nSe optarmos por incluir os dados nulos, podemos utilizar a opção dropna=False.\n\nvendas_europa['Order Priority'].value_counts(dropna=False)\n\nOrder Priority\nM      352\nL      334\nH      334\nC      304\nNaN      6\nName: count, dtype: int64\n\n\n\n\n\nPodemos inclusive plotar essa contagem, mas isso veremos com mais calma adiante.\n\n\nvendas_europa['Item Type'].value_counts().plot.barh(color='k', figsize=(6,4))"
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#duplicatas",
    "href": "sections/metodos_basicos_pandas.html#duplicatas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Sabemos que a coluna Sales Channel vai ter várias duplicatas (pois só poucas opções de valores para o canal de vendas). Logo vamos listar quais são os valores que contém duplicatas.\n\nvendas_europa['Sales Channel'].drop_duplicates()\n\n0    Offline\n1     Online\nName: Sales Channel, dtype: object\n\n\nAlternativamente, podemos listar um subset e listar duplicatas em relação a ele:\n\nvendas_europa.drop_duplicates(subset=['Country'])\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n5\nEurope\nMontenegro\nFruits\nOffline\nL\n5/29/2016\n313705861\n7/10/2016\n1390\n9.33\n6.92\n12968.70\n9618.80\n3349.90\n\n\n7\nEurope\nLuxembourg\nVegetables\nOffline\nL\n2/13/2010\n744683635\n4/1/2010\n7291\n154.06\n90.93\n1123251.46\n662970.63\n460280.83\n\n\n8\nEurope\nSwitzerland\nMeat\nOnline\nL\n3/21/2014\n169378983\n4/10/2014\n1860\n421.89\n364.69\n784715.40\n678323.40\n106392.00\n\n\n9\nEurope\nFinland\nBeverages\nOnline\nH\n3/16/2012\n566428315\n3/23/2012\n7581\n47.45\n31.79\n359718.45\n240999.99\n118718.46\n\n\n10\nEurope\nBelgium\nSnacks\nOnline\nM\n1/12/2015\n519380223\n1/17/2015\n5005\n152.58\n97.44\n763662.90\n487687.20\n275975.70\n\n\n11\nEurope\nSan Marino\nOffice Supplies\nOnline\nH\n4/13/2014\n904589211\n5/4/2014\n6905\n651.21\n524.96\n4496605.05\n3624848.80\n871756.25\n\n\n13\nEurope\nNetherlands\nMeat\nOffline\nM\n3/8/2017\n747774398\n4/3/2017\n1916\n421.89\n364.69\n808341.24\n698746.04\n109595.20\n\n\n14\nEurope\nRussia\nHousehold\nOnline\nM\n7/10/2017\n194176757\n8/20/2017\n72\n668.27\n502.54\n48115.44\n36182.88\n11932.56\n\n\n15\nEurope\nUkraine\nCosmetics\nOnline\nH\n1/22/2011\n773645913\n1/28/2011\n7873\n437.20\n263.33\n3442075.60\n2073197.09\n1368878.51\n\n\n17\nEurope\nLatvia\nMeat\nOffline\nM\n12/15/2011\n847317397\n12/18/2011\n8902\n421.89\n364.69\n3755664.78\n3246470.38\n509194.40\n\n\n18\nEurope\nSerbia\nBeverages\nOnline\nL\n9/3/2012\n599624192\n9/21/2012\n978\n47.45\n31.79\n46406.10\n31090.62\n15315.48\n\n\n19\nEurope\nPortugal\nOffice Supplies\nOnline\nM\n1/21/2014\n734318292\n3/4/2014\n9956\n651.21\n524.96\n6483446.76\n5226501.76\n1256945.00\n\n\n20\nEurope\nPoland\nHousehold\nOffline\nL\n7/7/2017\n232196319\n8/4/2017\n905\n668.27\n502.54\n604784.35\n454798.70\n149985.65\n\n\n21\nEurope\nLiechtenstein\nCosmetics\nOnline\nL\n7/15/2012\n229693067\n7/15/2012\n138\n437.20\n263.33\n60333.60\n36339.54\n23994.06\n\n\n22\nEurope\nUnited Kingdom\nBeverages\nOnline\nC\n4/8/2017\n121945512\n4/12/2017\n5242\n47.45\n31.79\n248732.90\n166643.18\n82089.72\n\n\n23\nEurope\nSlovenia\nFruits\nOnline\nH\n10/22/2012\n169799983\n11/20/2012\n6443\n9.33\n6.92\n60113.19\n44585.56\n15527.63\n\n\n24\nEurope\nMalta\nVegetables\nOnline\nM\n3/11/2014\n894589078\n4/10/2014\n7643\n154.06\n90.93\n1177480.58\n694977.99\n482502.59\n\n\n26\nEurope\nCyprus\nFruits\nOffline\nM\n7/12/2015\n600515115\n8/30/2015\n4622\n9.33\n6.92\n43123.26\n31984.24\n11139.02\n\n\n28\nEurope\nMonaco\nPersonal Care\nOnline\nL\n6/8/2014\n263098371\n7/4/2014\n5509\n81.73\n56.67\n450250.57\n312195.03\n138055.54\n\n\n30\nEurope\nNorway\nCereal\nOnline\nM\n10/8/2014\n100640618\n10/18/2014\n650\n205.70\n117.11\n133705.00\n76121.50\n57583.50\n\n\n33\nEurope\nArmenia\nFruits\nOnline\nM\n3/23/2011\n120977771\n5/2/2011\n8866\n9.33\n6.92\n82719.78\n61352.72\n21367.06\n\n\n35\nEurope\nDenmark\nBeverages\nOnline\nH\n6/5/2016\n973268353\n6/26/2016\n589\n47.45\n31.79\n27948.05\n18724.31\n9223.74\n\n\n37\nEurope\nKosovo\nFruits\nOnline\nL\n5/2/2010\n291995418\n6/6/2010\n6788\n9.33\n6.92\n63332.04\n46972.96\n16359.08\n\n\n38\nEurope\nHungary\nBaby Food\nOnline\nM\n1/25/2011\n128686225\n3/13/2011\n9968\n255.28\n159.42\n2544631.04\n1589098.56\n955532.48\n\n\n39\nEurope\nLithuania\nCosmetics\nOffline\nL\n1/6/2012\n420875346\n2/18/2012\n5223\n437.20\n263.33\n2283495.60\n1375372.59\n908123.01\n\n\n40\nEurope\nAlbania\nVegetables\nOnline\nC\n10/5/2012\n476633536\n11/3/2012\n5310\n154.06\n90.93\n818058.60\n482838.30\n335220.30\n\n\n42\nEurope\nMoldova\nPersonal Care\nOnline\nM\n3/11/2013\n467045819\n4/12/2013\n8092\n81.73\n56.67\n661359.16\n458573.64\n202785.52\n\n\n51\nEurope\nFrance\nMeat\nOnline\nL\n11/28/2015\n245440852\n12/17/2015\n257\n421.89\n364.69\n108425.73\n93725.33\n14700.40\n\n\n52\nEurope\nSpain\nFruits\nOnline\nH\n10/22/2011\n817006289\n11/14/2011\n9172\n9.33\n6.92\n85574.76\n63470.24\n22104.52\n\n\n53\nEurope\nSweden\nVegetables\nOnline\nH\n9/20/2010\n298228013\n10/25/2010\n1151\n154.06\n90.93\n177323.06\n104660.43\n72662.63\n\n\n59\nEurope\nMacedonia\nCosmetics\nOnline\nC\n12/26/2010\n350977408\n1/22/2011\n869\n437.20\n263.33\n379926.80\n228833.77\n151093.03\n\n\n60\nEurope\nGreece\nPersonal Care\nOffline\nNaN\n12/8/2011\n701298367\n1/6/2012\n8626\n81.73\n56.67\n705002.98\n488835.42\n216167.56\n\n\n61\nEurope\nItaly\nPersonal Care\nOnline\nC\n2/25/2011\n309342658\n3/28/2011\n222\n81.73\n56.67\n18144.06\n12580.74\n5563.32\n\n\n66\nEurope\nGermany\nBaby Food\nOffline\nL\n1/6/2017\n361311852\n2/15/2017\n9061\n255.28\n159.42\n2313092.08\n1444504.62\n868587.46\n\n\n78\nEurope\nAndorra\nCereal\nOnline\nH\n3/19/2010\n696197879\n3/26/2010\n9278\n205.70\n117.11\n1908484.60\n1086546.58\n821938.02\n\n\n79\nEurope\nIceland\nCosmetics\nOnline\nC\n4/5/2012\n907349526\n5/16/2012\n3743\n437.20\n263.33\n1636439.60\n985644.19\n650795.41\n\n\n83\nEurope\nCroatia\nBeverages\nOffline\nL\n2/22/2013\n189924275\n3/21/2013\n1668\n47.45\n31.79\n79146.60\n53025.72\n26120.88\n\n\n89\nEurope\nSlovakia\nHousehold\nOffline\nL\n2/20/2010\n585362994\n4/11/2010\n773\n668.27\n502.54\n516572.71\n388463.42\n128109.29\n\n\n96\nEurope\nVatican City\nBeverages\nOnline\nC\n12/27/2015\n370484149\n1/19/2016\n3348\n47.45\n31.79\n158862.60\n106432.92\n52429.68\n\n\n99\nEurope\nBelarus\nVegetables\nOnline\nL\n12/31/2012\n413078916\n1/11/2013\n8086\n154.06\n90.93\n1245729.16\n735259.98\n510469.18\n\n\n102\nEurope\nIreland\nVegetables\nOffline\nC\n11/16/2010\n901670968\n12/11/2010\n3331\n154.06\n90.93\n513173.86\n302887.83\n210286.03\n\n\n140\nEurope\nRomania\nSnacks\nOnline\nH\n8/18/2014\n747327220\n9/15/2014\n9587\n152.58\n97.44\n1462784.46\n934157.28\n528627.18\n\n\n152\nEurope\nGeorgia\nBaby Food\nOnline\nL\n1/26/2014\n359197413\n3/8/2014\n3352\n255.28\n159.42\n855698.56\n534375.84\n321322.72\n\n\n\n\n\n\n\nNote que retornou apenas países que contém duplicatas."
  },
  {
    "objectID": "sections/metodos_basicos_pandas.html#novas-colunas",
    "href": "sections/metodos_basicos_pandas.html#novas-colunas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Podemos também criar novas colunas. Vamos supor que se deseja obter os valores de Total Profit em real brasileiro (BRL ou R$) ao invés de dólar (USD). Considerando 1 BRL = 4,96 USD (16/02/2024, 12h50). Tem-se:\n\n# Transformando Total Profit em inteiro:\nvendas_europa['Total Profit'] = vendas_europa['Total Profit'].astype('int') \n\n# Convertendo USD para BRL:\nvendas_europa['Total Profit (BRL)'] = vendas_europa['Total Profit'] * 4.96\n\n# Visualizando o resultado:\nvendas_europa[['Total Profit (BRL)', 'Total Profit']].head()\n\n\n\n\n\n\n\n\nTotal Profit (BRL)\nTotal Profit\n\n\n\n\n0\n371122.08\n74823\n\n\n1\n337666.88\n68078\n\n\n2\n2467704.16\n497521\n\n\n3\n3923766.72\n791082\n\n\n4\n59262.08\n11948\n\n\n\n\n\n\n\nOutro exemplo seria:\n\n# Marcando a versão:\nvendas_europa['Version'] = '001'\n\n# Resultado:\nvendas_europa[['Total Profit (BRL)', 'Total Profit', 'Version']].head()\n\n\n\n\n\n\n\n\nTotal Profit (BRL)\nTotal Profit\nVersion\n\n\n\n\n0\n371122.08\n74823\n001\n\n\n1\n337666.88\n68078\n001\n\n\n2\n2467704.16\n497521\n001\n\n\n3\n3923766.72\n791082\n001\n\n\n4\n59262.08\n11948\n001"
  },
  {
    "objectID": "sections/leitura_arquivos.html",
    "href": "sections/leitura_arquivos.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Primeiramente, é importante entendermos as duas estrturuas que o Pandas trabalha: séries e dataframes. Ambas estruturas estão ilustradas na Figura a seguir. Ao longo das aulas, iremos trabalhar majoriatiaramente com dataframes.\n\n\n\nSeries vs Dataframes\n\n\nO Pandas permite ler diversos formatos de dados, desde planilhas em Excel (.xlsx), arquivos separados por vírgula (.csv), tabelas em páginas html, arquivos de texto (.txt), arquivos .json, entre outras possibilidades. Abaixo temos algumas delas:\n# arquivo de MS Excel:\ndados = pd.read_xlsx('ARQUIVO.xlsx', sheet_name='planilha')\n\n# arquivo csv (separado por vírgulas):\ndados = pd.read_csv('ARQUIVO.csv', delimiter=';')\n\n# arquivo de texto:\ndados = pd.read_txt('ARQUIVO.txt')\n\n# outros formatos (asc, txt, dat): \ndados = pd.read_fwf('ARQUIVO.asc')\n\n# tabela de página web (html):\ndados = pd.read_html('URL')[indice_tabela]\n\n# arquivo json:\ndados = pd.read_json('ARQUIVO.json')\nPrévio a coleta de dados, é sempre fundamental importar a biblioteca. Isso é realizado com o comando abaixo:\n\nimport pandas as pd\n\nFeito isso, vejamos alguns exemplos a seguir.\n\n\n\npreco_streamings = pd.read_excel('dados/preco_servicos_streaming/Streaming_prices.xlsx')\npreco_streamings\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n499\nApple TV+\nSep-2023\n6.99\n\n\n500\nApple TV+\nOct-2023\n6.99\n\n\n501\nApple TV+\nNov-2023\n6.99\n\n\n502\nApple TV+\nDec-2023\n6.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n504 rows × 3 columns\n\n\n\n\n\n\n\nvendas_europa = pd.read_csv('dados/vendas/EuropeSalesRecords.csv')\nvendas_europa\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n634033286\n1/15/2014\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n559183347\n5/21/2014\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n781416594\n12/23/2015\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n1330 rows × 14 columns\n\n\n\n\n\n\n\nenderecos_IP = pd.read_fwf('dados/enderecos_ip/ip_addresses.txt', delimiter='; ')\nenderecos_IP\n\n\n\n\n\n\n\n\nid\nip_address\n\n\n\n\n0\n1\n9.94.168.149\n\n\n1\n2\n79.89.169.206\n\n\n2\n3\n115.137.202.175\n\n\n3\n4\n226.167.14.232\n\n\n4\n5\n23.103.124.99\n\n\n5\n6\n140.112.160.33\n\n\n6\n7\n132.123.247.55\n\n\n7\n8\n183.24.63.45\n\n\n8\n9\n218.148.171.144\n\n\n9\n10\n217.152.48.198\n\n\n\n\n\n\n\n\n\n\n\n# OBS --- é preciso ter tabelas HTML para ler\n\nURL = 'https://pt.wikipedia.org/wiki/Demografia_do_Brasil'\n\ncrescimento_populacional = pd.read_html(URL)[3]\ncrescimento_populacional\n\n\n\n\n\n\n\n\nPaís\nCrianças (de 0 a 14 anos)\nJovens (de 15 a 24 anos)\nAdultos (de 25 a 64 anos)\nIdosos (a partir de 65 anos)\n\n\n\n\n0\nBrasil\n20,0%\n15,7%\n54,1%\n10,2%\n\n\n1\nReino Unido\n17,1%\n11,8%\n52,3%\n18,8%\n\n\n2\nMéxico\n24,3%\n17,0%\n50,8%\n7,9%\n\n\n3\nNigéria\n41,0%\n20,6%\n35,3%\n3,1%\n\n\n\n\n\n\n\n\n\n\nverificar quantas tabelas tem a página:\n\n\ncrescimento_populacional = pd.read_html(URL)\nlen(crescimento_populacional)\n\n18\n\n\n\n\n\n\n\ncorridas_app = pd.read_json('dados/corridas/corridas.json')\ncorridas_app\n\n\n\n\n\n\n\n\nid\norigem\ndestino\ndata_hora_inicio\ndata_hora_fim\nvalor\nmotorista\npassageiro\n\n\n\n\n0\n1\n{'latitude': -23.5505, 'longitude': -46.6333, ...\n{'latitude': -23.5667, 'longitude': -46.6667, ...\n2024-02-15T10:00:00\n2024-02-15T10:30:00\n25.50\n{'id': '789012345', 'nome': 'João da Silva', '...\n{'id': '987654321', 'nome': 'Maria Oliveira', ...\n\n\n1\n2\n{'latitude': -23.5603, 'longitude': -46.6619, ...\n{'latitude': -23.5675, 'longitude': -46.6515, ...\n2024-02-16T14:00:00\n2024-02-16T14:30:00\n30.75\n{'id': '789012346', 'nome': 'Ana Souza', 'carr...\n{'id': '987654322', 'nome': 'Carlos Santos', '...\n\n\n2\n3\n{'latitude': -23.5628, 'longitude': -46.6541, ...\n{'latitude': -23.5689, 'longitude': -46.6752, ...\n2024-02-17T08:30:00\n2024-02-17T09:00:00\n20.00\n{'id': '789012347', 'nome': 'Pedro Santos', 'c...\n{'id': '987654323', 'nome': 'Juliana Oliveira'...\n\n\n\n\n\n\n\n\n\n\nMais informações e opções podem ser encontradas na documentação oficial do Pandas (veja esse exemplo para o método pd.read_csv)"
  },
  {
    "objectID": "sections/leitura_arquivos.html#planilha-de-excel",
    "href": "sections/leitura_arquivos.html#planilha-de-excel",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "preco_streamings = pd.read_excel('dados/preco_servicos_streaming/Streaming_prices.xlsx')\npreco_streamings\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n499\nApple TV+\nSep-2023\n6.99\n\n\n500\nApple TV+\nOct-2023\n6.99\n\n\n501\nApple TV+\nNov-2023\n6.99\n\n\n502\nApple TV+\nDec-2023\n6.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n504 rows × 3 columns"
  },
  {
    "objectID": "sections/leitura_arquivos.html#arquivo-csv",
    "href": "sections/leitura_arquivos.html#arquivo-csv",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "vendas_europa = pd.read_csv('dados/vendas/EuropeSalesRecords.csv')\nvendas_europa\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n634033286\n1/15/2014\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n559183347\n5/21/2014\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n781416594\n12/23/2015\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n1330 rows × 14 columns"
  },
  {
    "objectID": "sections/leitura_arquivos.html#arquivo-txt",
    "href": "sections/leitura_arquivos.html#arquivo-txt",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "enderecos_IP = pd.read_fwf('dados/enderecos_ip/ip_addresses.txt', delimiter='; ')\nenderecos_IP\n\n\n\n\n\n\n\n\nid\nip_address\n\n\n\n\n0\n1\n9.94.168.149\n\n\n1\n2\n79.89.169.206\n\n\n2\n3\n115.137.202.175\n\n\n3\n4\n226.167.14.232\n\n\n4\n5\n23.103.124.99\n\n\n5\n6\n140.112.160.33\n\n\n6\n7\n132.123.247.55\n\n\n7\n8\n183.24.63.45\n\n\n8\n9\n218.148.171.144\n\n\n9\n10\n217.152.48.198"
  },
  {
    "objectID": "sections/leitura_arquivos.html#tabela-html",
    "href": "sections/leitura_arquivos.html#tabela-html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "# OBS --- é preciso ter tabelas HTML para ler\n\nURL = 'https://pt.wikipedia.org/wiki/Demografia_do_Brasil'\n\ncrescimento_populacional = pd.read_html(URL)[3]\ncrescimento_populacional\n\n\n\n\n\n\n\n\nPaís\nCrianças (de 0 a 14 anos)\nJovens (de 15 a 24 anos)\nAdultos (de 25 a 64 anos)\nIdosos (a partir de 65 anos)\n\n\n\n\n0\nBrasil\n20,0%\n15,7%\n54,1%\n10,2%\n\n\n1\nReino Unido\n17,1%\n11,8%\n52,3%\n18,8%\n\n\n2\nMéxico\n24,3%\n17,0%\n50,8%\n7,9%\n\n\n3\nNigéria\n41,0%\n20,6%\n35,3%\n3,1%\n\n\n\n\n\n\n\n\n\n\nverificar quantas tabelas tem a página:\n\n\ncrescimento_populacional = pd.read_html(URL)\nlen(crescimento_populacional)\n\n18"
  },
  {
    "objectID": "sections/leitura_arquivos.html#arquivo-json",
    "href": "sections/leitura_arquivos.html#arquivo-json",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "corridas_app = pd.read_json('dados/corridas/corridas.json')\ncorridas_app\n\n\n\n\n\n\n\n\nid\norigem\ndestino\ndata_hora_inicio\ndata_hora_fim\nvalor\nmotorista\npassageiro\n\n\n\n\n0\n1\n{'latitude': -23.5505, 'longitude': -46.6333, ...\n{'latitude': -23.5667, 'longitude': -46.6667, ...\n2024-02-15T10:00:00\n2024-02-15T10:30:00\n25.50\n{'id': '789012345', 'nome': 'João da Silva', '...\n{'id': '987654321', 'nome': 'Maria Oliveira', ...\n\n\n1\n2\n{'latitude': -23.5603, 'longitude': -46.6619, ...\n{'latitude': -23.5675, 'longitude': -46.6515, ...\n2024-02-16T14:00:00\n2024-02-16T14:30:00\n30.75\n{'id': '789012346', 'nome': 'Ana Souza', 'carr...\n{'id': '987654322', 'nome': 'Carlos Santos', '...\n\n\n2\n3\n{'latitude': -23.5628, 'longitude': -46.6541, ...\n{'latitude': -23.5689, 'longitude': -46.6752, ...\n2024-02-17T08:30:00\n2024-02-17T09:00:00\n20.00\n{'id': '789012347', 'nome': 'Pedro Santos', 'c...\n{'id': '987654323', 'nome': 'Juliana Oliveira'...\n\n\n\n\n\n\n\n\n\n\nMais informações e opções podem ser encontradas na documentação oficial do Pandas (veja esse exemplo para o método pd.read_csv)"
  },
  {
    "objectID": "sections/estatistica_com_pandas.html",
    "href": "sections/estatistica_com_pandas.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesta aula, vamos trabalhar com medidas de estatística descritiva em Pandas. Aqui, vamos utilizar um conjunto de dados disponível na biblioteca seaborn, uma biblioteca de visualização de dados. O conjunto de dados trata de contas e gorgetas em um restaurante fictício. O conteúdo a ser discutido é:\n\nMétodo describe()\nObtenção de valores máximo e mínimo, além da amplitdue dos dados\nMedidas de tendência central: média, mediana e moda\nMedidas de dispersão: desvio padrão, variância, coeficiente de variação\nMedidas de posição: quartis, percentis, mediana\nOutliers via método IQR\nCorrelação entre variáveis.\n\nPrimeiramente, vamos carregar o conjunto de dados tips, além das bibliotecas necessárias:\n\nimport pandas as pd\nimport seaborn as sns\n\ntips = sns.load_dataset('tips')\ntips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\n\nAs estatísticas descritivas podem ser obtidas pelo método .describe()\n\n# Vamos mostrar a tabela transposta (T) fins de visualização (linhas viram colunas):\ntips.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntotal_bill\n244.0\n19.785943\n8.902412\n3.07\n13.3475\n17.795\n24.1275\n50.81\n\n\ntip\n244.0\n2.998279\n1.383638\n1.00\n2.0000\n2.900\n3.5625\n10.00\n\n\nsize\n244.0\n2.569672\n0.951100\n1.00\n2.0000\n2.000\n3.0000\n6.00\n\n\n\n\n\n\n\nNesse dataframe de saída temos:\n\n\n\nColuna\nDescrição\n\n\n\n\nCOUNT\nContagem\n\n\nMEAN\nMédia\n\n\nSTD\nDesvio padrão\n\n\nMIN\nValor mínimo\n\n\n25%\nPrimeiro quartil (Q1, 25% dos dados)\n\n\n50%\nSegundo quartil ou mediana (Q2, 50% dos dados)\n\n\n75%\nTerceiro quartil (Q3, 75% dos dados)\n\n\nMAX\nValor máximo\n\n\n\n\n\n\nCaso queiramos menter dados categóricos também, podemos incluir a opção include='all'.\n\n\n\n\n\nCom essas medidas, podemos responder algumas perguntas.\n\nQual foi a gorjeta mínima?\n\n\ntips['tip'].min()\n\n1.0\n\n\n\nQual foi a maior conta (máximo total_bill)?\n\n\ntips['total_bill'].max()\n\n50.81\n\n\nLogo a amplitude dos dados (para a coluna tip) pode ser obtida por:\n\\[\nA = Max - Min\n\\]\n\namplitude_gorjetas = tips['tip'].max() - tips['tip'].min()\namplitude_gorjetas\n\n9.0\n\n\n\n\n\n\nMédia\n\n\ntips['tip'].mean()\n\n2.99827868852459\n\n\n\nMediana\n\n\ntips['total_bill'].mode()\n\n0    13.42\nName: total_bill, dtype: float64\n\n\n\nModa\n\n\ntips['day'].mode()\n\n0    Sat\nName: day, dtype: category\nCategories (4, object): ['Thur', 'Fri', 'Sat', 'Sun']\n\n\nConferindo:\n\ntips['day'].value_counts()\n\nday\nSat     87\nSun     76\nThur    62\nFri     19\nName: count, dtype: int64\n\n\n\n\n\n\nDesvio Padrão\n\n\n# Amostra (padrão, ddof=1):\nprint(tips['tip'].std())\n\n# População:\nprint(tips['tip'].std(ddof=0))\n\n1.3836381890011822\n1.3807999538298954\n\n\n\nVariância\n\n\n# Amostra (padrão, ddof=1):\nprint(tips['tip'].var())\n\n# População:\nprint(tips['tip'].var(ddof=0))\n\n1.914454638062471\n1.9066085124966412\n\n\n\nCoeficiente de variação (CV)\n\n\n# Amostra:\ncv_gorjeta = tips['tip'].std(ddof=1) / tips['tip'].mean() *100\ncv_gorjeta = round(cv_gorjeta, 2)\nprint(f' CV para tip: {cv_gorjeta}')\n\n CV para tip: 46.15\n\n\n\n\n\n\nQuartis\n\n\nQ1 = tips['tip'].quantile(0.25)\nQ2 = tips['tip'].quantile(0.5)\nQ3 = tips['tip'].quantile(0.75)\n\nprint(f'Q1 (25%): {Q1}')\nprint(f'Q2 (50%): {Q2}')\nprint(f'Q3 (75%): {Q3}')\n\nQ1 (25%): 2.0\nQ2 (50%): 2.9\nQ3 (75%): 3.5625\n\n\nIsso diz muito sobre a distribuição dos dados e pode ser visualizado por um boxplot:\nsns.boxplot(data=tips, x='tip', width=0.2, palette='viridis_r')\n\n\n\nBoxplot\n\n\n\nPercentis\n\n\n# Percentil 90°:\ntips['tip'].quantile(0.9)\n\n5.0\n\n\n\n\n\nA partir do conhecimento dos quartis e da distância inter-quartil (IQR), dada pela diferença Q3-Q1, podemos encontrar outliers (valores discrepantes):\n\\[\nOutliers \\ Inferiores = Q_1 - 1.5 IQR\n\\]\n\\[\nOutliers \\ Superiores = Q_3 + 1.5 IQR\n\\]\nAssim, vamos encontrar outliers para a coluna total_bill.\n\nIQR = tips['total_bill'].quantile(0.75) - tips['total_bill'].quantile(0.25)\noutliers_inf = tips['total_bill'].quantile(0.25) - 1.5*IQR\noutliers_sup = tips['total_bill'].quantile(0.75) + 1.5*IQR\n\nprint(f'Outliers inferiores: {outliers_inf}')\nprint(f'Outliers superiores: {outliers_sup}')\n\nOutliers inferiores: -2.8224999999999945\nOutliers superiores: 40.29749999999999\n\n\nDo ponto de vista prático, gorjeta negativa não faz nenhum sentido. Logo, podemos concluir que só temos outliers superiores. Podemos visualizar esses outliers por meio de um boxplot:\nsns.boxplot(data=tips, x='total_bill', width=0.2, palette='viridis_r')\n\n\n\nBoxplot\n\n\n\n\n\n\nParamétrica\n\n\n# Default: .corr(method='pearson')\ncorrelacoes = tips[['tip', 'total_bill']].corr()\ncorrelacoes\n\n\n\n\n\n\n\n\ntip\ntotal_bill\n\n\n\n\ntip\n1.000000\n0.675734\n\n\ntotal_bill\n0.675734\n1.000000\n\n\n\n\n\n\n\nÉ possível visualizar essas correlção via heatmap:\nsns.heatmap(correlacoes, annot=True, cmap='YlGnBu')\n\n\n\nHeatmap correlação de Pearson\n\n\n\nNão-paramétrica\n\n# Default: Pearson\ncorrelacoes_spearman = tips[['tip', 'total_bill']].corr(method='spearman')\nsns.heatmap(correlacoes_spearman, annot=True, cmap='YlGnBu')\n\n\n\nHeatmap correlação de Spearman"
  },
  {
    "objectID": "sections/estatistica_com_pandas.html#estatísticas-descritivas",
    "href": "sections/estatistica_com_pandas.html#estatísticas-descritivas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "As estatísticas descritivas podem ser obtidas pelo método .describe()\n\n# Vamos mostrar a tabela transposta (T) fins de visualização (linhas viram colunas):\ntips.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntotal_bill\n244.0\n19.785943\n8.902412\n3.07\n13.3475\n17.795\n24.1275\n50.81\n\n\ntip\n244.0\n2.998279\n1.383638\n1.00\n2.0000\n2.900\n3.5625\n10.00\n\n\nsize\n244.0\n2.569672\n0.951100\n1.00\n2.0000\n2.000\n3.0000\n6.00\n\n\n\n\n\n\n\nNesse dataframe de saída temos:\n\n\n\nColuna\nDescrição\n\n\n\n\nCOUNT\nContagem\n\n\nMEAN\nMédia\n\n\nSTD\nDesvio padrão\n\n\nMIN\nValor mínimo\n\n\n25%\nPrimeiro quartil (Q1, 25% dos dados)\n\n\n50%\nSegundo quartil ou mediana (Q2, 50% dos dados)\n\n\n75%\nTerceiro quartil (Q3, 75% dos dados)\n\n\nMAX\nValor máximo\n\n\n\n\n\n\nCaso queiramos menter dados categóricos também, podemos incluir a opção include='all'."
  },
  {
    "objectID": "sections/estatistica_com_pandas.html#mínimo-máximo-e-amplitude",
    "href": "sections/estatistica_com_pandas.html#mínimo-máximo-e-amplitude",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Com essas medidas, podemos responder algumas perguntas.\n\nQual foi a gorjeta mínima?\n\n\ntips['tip'].min()\n\n1.0\n\n\n\nQual foi a maior conta (máximo total_bill)?\n\n\ntips['total_bill'].max()\n\n50.81\n\n\nLogo a amplitude dos dados (para a coluna tip) pode ser obtida por:\n\\[\nA = Max - Min\n\\]\n\namplitude_gorjetas = tips['tip'].max() - tips['tip'].min()\namplitude_gorjetas\n\n9.0"
  },
  {
    "objectID": "sections/estatistica_com_pandas.html#medidas-de-tendência-central",
    "href": "sections/estatistica_com_pandas.html#medidas-de-tendência-central",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Média\n\n\ntips['tip'].mean()\n\n2.99827868852459\n\n\n\nMediana\n\n\ntips['total_bill'].mode()\n\n0    13.42\nName: total_bill, dtype: float64\n\n\n\nModa\n\n\ntips['day'].mode()\n\n0    Sat\nName: day, dtype: category\nCategories (4, object): ['Thur', 'Fri', 'Sat', 'Sun']\n\n\nConferindo:\n\ntips['day'].value_counts()\n\nday\nSat     87\nSun     76\nThur    62\nFri     19\nName: count, dtype: int64"
  },
  {
    "objectID": "sections/estatistica_com_pandas.html#medidas-de-dispersão",
    "href": "sections/estatistica_com_pandas.html#medidas-de-dispersão",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Desvio Padrão\n\n\n# Amostra (padrão, ddof=1):\nprint(tips['tip'].std())\n\n# População:\nprint(tips['tip'].std(ddof=0))\n\n1.3836381890011822\n1.3807999538298954\n\n\n\nVariância\n\n\n# Amostra (padrão, ddof=1):\nprint(tips['tip'].var())\n\n# População:\nprint(tips['tip'].var(ddof=0))\n\n1.914454638062471\n1.9066085124966412\n\n\n\nCoeficiente de variação (CV)\n\n\n# Amostra:\ncv_gorjeta = tips['tip'].std(ddof=1) / tips['tip'].mean() *100\ncv_gorjeta = round(cv_gorjeta, 2)\nprint(f' CV para tip: {cv_gorjeta}')\n\n CV para tip: 46.15"
  },
  {
    "objectID": "sections/estatistica_com_pandas.html#medidas-de-posição",
    "href": "sections/estatistica_com_pandas.html#medidas-de-posição",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Quartis\n\n\nQ1 = tips['tip'].quantile(0.25)\nQ2 = tips['tip'].quantile(0.5)\nQ3 = tips['tip'].quantile(0.75)\n\nprint(f'Q1 (25%): {Q1}')\nprint(f'Q2 (50%): {Q2}')\nprint(f'Q3 (75%): {Q3}')\n\nQ1 (25%): 2.0\nQ2 (50%): 2.9\nQ3 (75%): 3.5625\n\n\nIsso diz muito sobre a distribuição dos dados e pode ser visualizado por um boxplot:\nsns.boxplot(data=tips, x='tip', width=0.2, palette='viridis_r')\n\n\n\nBoxplot\n\n\n\nPercentis\n\n\n# Percentil 90°:\ntips['tip'].quantile(0.9)\n\n5.0"
  },
  {
    "objectID": "sections/estatistica_com_pandas.html#outliers-via-método-iqr",
    "href": "sections/estatistica_com_pandas.html#outliers-via-método-iqr",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "A partir do conhecimento dos quartis e da distância inter-quartil (IQR), dada pela diferença Q3-Q1, podemos encontrar outliers (valores discrepantes):\n\\[\nOutliers \\ Inferiores = Q_1 - 1.5 IQR\n\\]\n\\[\nOutliers \\ Superiores = Q_3 + 1.5 IQR\n\\]\nAssim, vamos encontrar outliers para a coluna total_bill.\n\nIQR = tips['total_bill'].quantile(0.75) - tips['total_bill'].quantile(0.25)\noutliers_inf = tips['total_bill'].quantile(0.25) - 1.5*IQR\noutliers_sup = tips['total_bill'].quantile(0.75) + 1.5*IQR\n\nprint(f'Outliers inferiores: {outliers_inf}')\nprint(f'Outliers superiores: {outliers_sup}')\n\nOutliers inferiores: -2.8224999999999945\nOutliers superiores: 40.29749999999999\n\n\nDo ponto de vista prático, gorjeta negativa não faz nenhum sentido. Logo, podemos concluir que só temos outliers superiores. Podemos visualizar esses outliers por meio de um boxplot:\nsns.boxplot(data=tips, x='total_bill', width=0.2, palette='viridis_r')\n\n\n\nBoxplot"
  },
  {
    "objectID": "sections/estatistica_com_pandas.html#correlação-entre-variáveis",
    "href": "sections/estatistica_com_pandas.html#correlação-entre-variáveis",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Paramétrica\n\n\n# Default: .corr(method='pearson')\ncorrelacoes = tips[['tip', 'total_bill']].corr()\ncorrelacoes\n\n\n\n\n\n\n\n\ntip\ntotal_bill\n\n\n\n\ntip\n1.000000\n0.675734\n\n\ntotal_bill\n0.675734\n1.000000\n\n\n\n\n\n\n\nÉ possível visualizar essas correlção via heatmap:\nsns.heatmap(correlacoes, annot=True, cmap='YlGnBu')\n\n\n\nHeatmap correlação de Pearson\n\n\n\nNão-paramétrica\n\n# Default: Pearson\ncorrelacoes_spearman = tips[['tip', 'total_bill']].corr(method='spearman')\nsns.heatmap(correlacoes_spearman, annot=True, cmap='YlGnBu')\n\n\n\nHeatmap correlação de Spearman"
  },
  {
    "objectID": "notebooks/leitura_arquivos.html",
    "href": "notebooks/leitura_arquivos.html",
    "title": "Leitura de arquivos",
    "section": "",
    "text": "Leitura de arquivos\n# arquivo de MS Excel:\ndados = pd.read_xlsx('ARQUIVO.xlsx', sheet_name='planilha')\n\n# arquivo csv (separado por vírgulas):\ndados = pd.read_csv('ARQUIVO.csv', delimiter=';')\n\n# arquivo de texto:\ndados = pd.read_txt('ARQUIVO.txt')\n\n# outros formatos (asc, txt, dat): \ndados = pd.read_fwf('ARQUIVO.asc')\n\n# tabela de página web (html):\ndados = pd.read_html('URL')[indice_tabela]\n\n# arquivo json:\ndados = pd.read_json('ARQUIVO.json')"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Sobre o material\nEsse é um material de apoio para o curso “Manipulacao de Dados com Pandas” disponível na Udemy - em breve.\nO curso trata sobre 8 módulos:\n\nLeitura de arquivos\nMétodos básicos do Pandas\nSlicing e filtros\nMétodos estatísticos\nAgregações\nJunções\nLimpeza de dados\nVisualização de dados\n\n\n\nSobre o autor\nAnalista de Dados & Editor LaTeX, auta como profissional autônomo, tendo prestado serviços a nivel nacional e internacional a clientes de mais de 30 países. Conta com mais de 200 projetos conclusos.\n\nGitHub: OviedoVR | Linkedin: Perfil"
  },
  {
    "objectID": "sections/agregacoes.html",
    "href": "sections/agregacoes.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesta aula, vamos trabalhar com agregação de dados com Pandas. É uma aula mais curta, comparada às anteriores, porém permite um leque de possibilidades. Veremos:\n\nMétodo groupby\nMétodo agg\n\nPara isso, utilizaremos o conjunto de dados sobre vendas.\n\nimport pandas as pd\n\nvendas_europa = pd.read_csv('dados/vendas/EuropeSalesRecords.csv')\nvendas_europa.head()\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n\n\n\n\n\n\n\nNesse método, podemos agrupar dados com base em categorias e precisamos obrigatoriamente informar uma medida de agregação (e.g, soma, média, mediana, desvio padrão, etc.). Começemos com uma pergunta de negócio.\n\nQual foi o faturamento total por país? (usemos 1 casas decimal)\n\n\nvendas_europa.groupby('Country')['Total Revenue'].sum().round(1)\n\nCountry\nAlbania                   32224853.9\nAndorra                   47756693.2\nArmenia                   37519840.2\nAustria                   35740871.5\nBelarus                   34236260.8\nBelgium                   25852572.3\nBosnia and Herzegovina    50117508.5\nBulgaria                  38161555.7\nCroatia                   27348195.7\nCyprus                    33008851.5\nCzech Republic            53543932.1\nDenmark                   26968532.5\nEstonia                   23410001.8\nFinland                   26027949.0\nFrance                    39362112.2\nGeorgia                   22802195.7\nGermany                   38055087.6\nGreece                    38699541.7\nHungary                   42408249.1\nIceland                   25570227.4\nIreland                   33022223.3\nItaly                     35878352.1\nKosovo                    53833142.8\nLatvia                    38722084.2\nLiechtenstein             29872564.4\nLithuania                 29031942.1\nLuxembourg                33075377.2\nMacedonia                 49222085.2\nMalta                     47145320.8\nMoldova                   27031700.1\nMonaco                    13828738.2\nMontenegro                31346476.9\nNetherlands               20860788.8\nNorway                    31520698.5\nPoland                    33805403.2\nPortugal                  47172189.8\nRomania                   34286150.8\nRussia                    46051659.8\nSan Marino                47883708.5\nSerbia                    42193537.7\nSlovakia                  42940998.3\nSlovenia                  38892531.3\nSpain                     27644278.7\nSweden                    35482128.0\nSwitzerland               31875174.0\nUkraine                   53252317.5\nUnited Kingdom            26654989.5\nVatican City              22280804.1\nName: Total Revenue, dtype: float64\n\n\nNote que country veio como inídice, mas podemos deixar as categorias como linhas convencionais (usando as_index=False) e adicionar mais de uma categoria. Para isso, vamos responder a outra pergunta.\n\nQual foi o lucro médio em cada país por canal de venda? listemos o top 5\n\n\n# Agregação:\nlucro_medio_pais_e_canal = vendas_europa.groupby('Country', as_index=False)['Total Profit'].sum().round(1)\n\n# Ordenação dos dados:\nlucro_medio_pais_e_canal = lucro_medio_pais_e_canal.sort_values(\n  by='Total Profit', ascending=False\n)\n\n# Visualização dos resultados:\nlucro_medio_pais_e_canal.head()\n\n\n\n\n\n\n\n\nCountry\nTotal Profit\n\n\n\n\n1\nAndorra\n15410036.6\n\n\n45\nUkraine\n14804925.7\n\n\n28\nMalta\n14610127.9\n\n\n22\nKosovo\n14409145.4\n\n\n38\nSan Marino\n13792992.8\n\n\n\n\n\n\n\n\n\n\nEsse metodo serve para utilizarmos mais de uma medida de agregação. No caso da pergunta anterior, só a média não nos diz muita coisa. Em outras palavras, é uma boa prática mostrar o desvio padrão junto à média. Assim, temos uma noção da variabilidade dos dados e se a média de fato representa bem nosso conjunto de dados. Vamos utilizar a mesma lógica da pergunta anterior, mas mostrando os 5 piores em termos de lucro.\n\n# Agregação:\nvendas_europa.groupby(['Country', 'Sales Channel'])['Total Profit']\\\n  .agg(['mean', 'std', 'median']).tail()\n\n\n\n\n\n\n\n\n\nmean\nstd\nmedian\n\n\nCountry\nSales Channel\n\n\n\n\n\n\n\nUkraine\nOnline\n540192.216250\n461192.942092\n419867.210\n\n\nUnited Kingdom\nOffline\n386919.697143\n400336.448858\n250574.940\n\n\nOnline\n413617.145625\n457835.010825\n216474.465\n\n\nVatican City\nOffline\n262827.323125\n298981.868340\n115792.650\n\n\nOnline\n315512.177143\n197270.837319\n272952.500\n\n\n\n\n\n\n\nOutra opção é:\n\n# Agregação:\nvendas_europa.groupby(['Country', 'Sales Channel'])['Total Profit'].describe()\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nCountry\nSales Channel\n\n\n\n\n\n\n\n\n\n\n\n\nAlbania\nOffline\n11.0\n614448.018182\n612231.249278\n35454.24\n79415.0400\n543430.340\n890054.8050\n1672455.53\n\n\nOnline\n10.0\n373177.782000\n399647.088296\n17601.84\n63175.9350\n229644.635\n625957.5150\n1107843.75\n\n\nAndorra\nOffline\n18.0\n249127.326111\n315220.845804\n2369.03\n25045.9475\n126314.510\n413880.4275\n1245958.14\n\n\nOnline\n22.0\n496624.761818\n497687.329727\n24194.70\n108122.5350\n347167.260\n712274.5800\n1700448.60\n\n\nArmenia\nOffline\n16.0\n385731.609375\n347925.918412\n8492.84\n91203.5000\n402212.320\n499465.2850\n1236511.53\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nUkraine\nOnline\n16.0\n540192.216250\n461192.942092\n28141.02\n172150.1700\n419867.210\n767868.0850\n1574045.11\n\n\nUnited Kingdom\nOffline\n7.0\n386919.697143\n400336.448858\n17568.90\n131640.1800\n250574.940\n491785.0000\n1193443.68\n\n\nOnline\n16.0\n413617.145625\n457835.010825\n9033.12\n77568.1000\n216474.465\n598346.2875\n1531273.09\n\n\nVatican City\nOffline\n16.0\n262827.323125\n298981.868340\n16419.33\n44425.1150\n115792.650\n385834.8300\n1016587.82\n\n\nOnline\n7.0\n315512.177143\n197270.837319\n52429.68\n196048.0750\n272952.500\n449443.3750\n592220.16\n\n\n\n\n96 rows × 8 columns"
  },
  {
    "objectID": "sections/agregacoes.html#método-groupby",
    "href": "sections/agregacoes.html#método-groupby",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesse método, podemos agrupar dados com base em categorias e precisamos obrigatoriamente informar uma medida de agregação (e.g, soma, média, mediana, desvio padrão, etc.). Começemos com uma pergunta de negócio.\n\nQual foi o faturamento total por país? (usemos 1 casas decimal)\n\n\nvendas_europa.groupby('Country')['Total Revenue'].sum().round(1)\n\nCountry\nAlbania                   32224853.9\nAndorra                   47756693.2\nArmenia                   37519840.2\nAustria                   35740871.5\nBelarus                   34236260.8\nBelgium                   25852572.3\nBosnia and Herzegovina    50117508.5\nBulgaria                  38161555.7\nCroatia                   27348195.7\nCyprus                    33008851.5\nCzech Republic            53543932.1\nDenmark                   26968532.5\nEstonia                   23410001.8\nFinland                   26027949.0\nFrance                    39362112.2\nGeorgia                   22802195.7\nGermany                   38055087.6\nGreece                    38699541.7\nHungary                   42408249.1\nIceland                   25570227.4\nIreland                   33022223.3\nItaly                     35878352.1\nKosovo                    53833142.8\nLatvia                    38722084.2\nLiechtenstein             29872564.4\nLithuania                 29031942.1\nLuxembourg                33075377.2\nMacedonia                 49222085.2\nMalta                     47145320.8\nMoldova                   27031700.1\nMonaco                    13828738.2\nMontenegro                31346476.9\nNetherlands               20860788.8\nNorway                    31520698.5\nPoland                    33805403.2\nPortugal                  47172189.8\nRomania                   34286150.8\nRussia                    46051659.8\nSan Marino                47883708.5\nSerbia                    42193537.7\nSlovakia                  42940998.3\nSlovenia                  38892531.3\nSpain                     27644278.7\nSweden                    35482128.0\nSwitzerland               31875174.0\nUkraine                   53252317.5\nUnited Kingdom            26654989.5\nVatican City              22280804.1\nName: Total Revenue, dtype: float64\n\n\nNote que country veio como inídice, mas podemos deixar as categorias como linhas convencionais (usando as_index=False) e adicionar mais de uma categoria. Para isso, vamos responder a outra pergunta.\n\nQual foi o lucro médio em cada país por canal de venda? listemos o top 5\n\n\n# Agregação:\nlucro_medio_pais_e_canal = vendas_europa.groupby('Country', as_index=False)['Total Profit'].sum().round(1)\n\n# Ordenação dos dados:\nlucro_medio_pais_e_canal = lucro_medio_pais_e_canal.sort_values(\n  by='Total Profit', ascending=False\n)\n\n# Visualização dos resultados:\nlucro_medio_pais_e_canal.head()\n\n\n\n\n\n\n\n\nCountry\nTotal Profit\n\n\n\n\n1\nAndorra\n15410036.6\n\n\n45\nUkraine\n14804925.7\n\n\n28\nMalta\n14610127.9\n\n\n22\nKosovo\n14409145.4\n\n\n38\nSan Marino\n13792992.8"
  },
  {
    "objectID": "sections/agregacoes.html#método-agg",
    "href": "sections/agregacoes.html#método-agg",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Esse metodo serve para utilizarmos mais de uma medida de agregação. No caso da pergunta anterior, só a média não nos diz muita coisa. Em outras palavras, é uma boa prática mostrar o desvio padrão junto à média. Assim, temos uma noção da variabilidade dos dados e se a média de fato representa bem nosso conjunto de dados. Vamos utilizar a mesma lógica da pergunta anterior, mas mostrando os 5 piores em termos de lucro.\n\n# Agregação:\nvendas_europa.groupby(['Country', 'Sales Channel'])['Total Profit']\\\n  .agg(['mean', 'std', 'median']).tail()\n\n\n\n\n\n\n\n\n\nmean\nstd\nmedian\n\n\nCountry\nSales Channel\n\n\n\n\n\n\n\nUkraine\nOnline\n540192.216250\n461192.942092\n419867.210\n\n\nUnited Kingdom\nOffline\n386919.697143\n400336.448858\n250574.940\n\n\nOnline\n413617.145625\n457835.010825\n216474.465\n\n\nVatican City\nOffline\n262827.323125\n298981.868340\n115792.650\n\n\nOnline\n315512.177143\n197270.837319\n272952.500\n\n\n\n\n\n\n\nOutra opção é:\n\n# Agregação:\nvendas_europa.groupby(['Country', 'Sales Channel'])['Total Profit'].describe()\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nCountry\nSales Channel\n\n\n\n\n\n\n\n\n\n\n\n\nAlbania\nOffline\n11.0\n614448.018182\n612231.249278\n35454.24\n79415.0400\n543430.340\n890054.8050\n1672455.53\n\n\nOnline\n10.0\n373177.782000\n399647.088296\n17601.84\n63175.9350\n229644.635\n625957.5150\n1107843.75\n\n\nAndorra\nOffline\n18.0\n249127.326111\n315220.845804\n2369.03\n25045.9475\n126314.510\n413880.4275\n1245958.14\n\n\nOnline\n22.0\n496624.761818\n497687.329727\n24194.70\n108122.5350\n347167.260\n712274.5800\n1700448.60\n\n\nArmenia\nOffline\n16.0\n385731.609375\n347925.918412\n8492.84\n91203.5000\n402212.320\n499465.2850\n1236511.53\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nUkraine\nOnline\n16.0\n540192.216250\n461192.942092\n28141.02\n172150.1700\n419867.210\n767868.0850\n1574045.11\n\n\nUnited Kingdom\nOffline\n7.0\n386919.697143\n400336.448858\n17568.90\n131640.1800\n250574.940\n491785.0000\n1193443.68\n\n\nOnline\n16.0\n413617.145625\n457835.010825\n9033.12\n77568.1000\n216474.465\n598346.2875\n1531273.09\n\n\nVatican City\nOffline\n16.0\n262827.323125\n298981.868340\n16419.33\n44425.1150\n115792.650\n385834.8300\n1016587.82\n\n\nOnline\n7.0\n315512.177143\n197270.837319\n52429.68\n196048.0750\n272952.500\n449443.3750\n592220.16\n\n\n\n\n96 rows × 8 columns"
  },
  {
    "objectID": "sections/juncoes.html",
    "href": "sections/juncoes.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesta aula, vamos trabalhar com a junção de dois ou mais dataframes utilizando dois métodos:\n\nConcatenação: via método concat\nJunções: via método merge\n\nIsso é muito útil quanto temos dados em duas tabelas diferentes, mas que possuem relação entre si e, logo, podem ser cruzados para a obtenção de insights.\n\n\nConsideremos dois dataframes distintos que trazem preços de café em três determinadas lojas, nos dias 18/02/2024 e 19/02/2024, respectivamente.\n\nimport pandas as pd\n\nprecos_cafe_18022024 = pd.read_csv('dados/preco_cafes/precos_cafe_dia18.csv')\nprecos_cafe_19022024 = pd.read_csv('dados/preco_cafes/precos_cafe_dia19.csv')\n\n\nDia 18-02-204:\n\n\nprecos_cafe_18022024.head()\n\n\n\n\n\n\n\n\nData\nTipo_cafe\nPreco_loja_A\nPreco_loja_B\nPreco_loja_C\n\n\n\n\n0\n2024-02-18\nCafé Tradicional\n5.99\n6.49\n5.79\n\n\n1\n2024-02-18\nCafé Espresso\n3.49\n3.99\n3.29\n\n\n2\n2024-02-18\nCafé Descafeinado\n6.99\n7.49\n6.79\n\n\n\n\n\n\n\n\nDia 19-02-204:\n\n\nprecos_cafe_19022024.head()\n\n\n\n\n\n\n\n\nData\nTipo_cafe\nPreco_loja_A\nPreco_loja_B\nPreco_loja_C\n\n\n\n\n0\n2024-02-19\nCafé Tradicional\n5.89\n6.59\n5.69\n\n\n1\n2024-02-19\nCafé Espresso\n3.59\n4.09\n3.39\n\n\n2\n2024-02-19\nCafé Descafeinado\n6.79\n7.59\n6.89\n\n\n\n\n\n\n\nFrequentemente, precisamos consolidar dados, isto é, unificar esses dois ou mais dataframes, já que eles tratam do mesmo assunto. Isso facilita possíveis análises posteriores. Logo, podemos concatenar esses dataframes tanto na direção das linhas (axis=0) quanto na diração das colunas (axis=1), como mostra a Figura abaixo.\n\n\n\nConcatenação de dataframes\n\n\nNesse caso, fica nítido que a concatenação deve ocorrer no eixo das linhas. Isso pode ser feito da seguinte maneira:\n\n# pd.concat([df_1, df_2], axis=EIXO, ignore_index=True):\npreco_cafes = pd.concat(\n  [precos_cafe_18022024, precos_cafe_19022024], \n  axis=0, ignore_index=True\n)\n\n# visualizando o resultado:\npreco_cafes\n\n\n\n\n\n\n\n\nData\nTipo_cafe\nPreco_loja_A\nPreco_loja_B\nPreco_loja_C\n\n\n\n\n0\n2024-02-18\nCafé Tradicional\n5.99\n6.49\n5.79\n\n\n1\n2024-02-18\nCafé Espresso\n3.49\n3.99\n3.29\n\n\n2\n2024-02-18\nCafé Descafeinado\n6.99\n7.49\n6.79\n\n\n3\n2024-02-19\nCafé Tradicional\n5.89\n6.59\n5.69\n\n\n4\n2024-02-19\nCafé Espresso\n3.59\n4.09\n3.39\n\n\n5\n2024-02-19\nCafé Descafeinado\n6.79\n7.59\n6.89\n\n\n\n\n\n\n\n\n\n\nBasicamente, estes vários tipos de junções possíveis com este método - a Figura abaixo ilustra algumas.\n\n\n\nTipos de junções\n\n\nPara ilustrar os três primeiros casos (inner, left e right), criaremos dois dataframes para funcionários e dapartamentos.\nRegistro dos clientes (cadastro):\n\n# DataFrame de funcionários:\nfuncionarios = pd.DataFrame({\n    'ID_funcionario': [1, 2, 3, 4, 5],\n    'Nome': ['João', 'Maria', 'Pedro', 'Ana', 'Paula'],\n    'Departamento_ID': [101, 102, 101, 103, 102]\n})\n\nfuncionarios\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\n\n\n\n\n0\n1\nJoão\n101\n\n\n1\n2\nMaria\n102\n\n\n2\n3\nPedro\n101\n\n\n3\n4\nAna\n103\n\n\n4\n5\nPaula\n102\n\n\n\n\n\n\n\nRegistro dos departamentos:\n\n# DataFrame de departamentos:\ndepartamentos = pd.DataFrame({\n    'ID_depto': [101, 102, 103, 104],\n    'Departamento': ['Vendas', 'Marketing', 'TI', 'RH']\n})\n\ndepartamentos\n\n\n\n\n\n\n\n\nID_depto\nDepartamento\n\n\n\n\n0\n101\nVendas\n\n\n1\n102\nMarketing\n\n\n2\n103\nTI\n\n\n3\n104\nRH\n\n\n\n\n\n\n\n\nJunção inner join\n\nNesse caso queremos a intersecção entre os dataframes A e B, isto é, aquilo que é comum a ambos apenas.\n\n# Inner Join: retorna apenas os registros comuns aos dois dataframes\ninner_join = pd.merge(\n  funcionarios, departamentos, \n  how='inner', \n  left_on='Departamento_ID', \n  right_on='ID_depto'\n)\n\ninner_join\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\nID_depto\nDepartamento\n\n\n\n\n0\n1\nJoão\n101\n101\nVendas\n\n\n1\n3\nPedro\n101\n101\nVendas\n\n\n2\n2\nMaria\n102\n102\nMarketing\n\n\n3\n5\nPaula\n102\n102\nMarketing\n\n\n4\n4\nAna\n103\n103\nTI\n\n\n\n\n\n\n\n\nJunção left join/right join\n\nNeste caso, desejamos obter os dados de A mais a interseção de A e B (todo os dados de A, mais o que há de comum entre A e B) - no left.\n\n# Left Join: retorna todos os registros do dataframe da esquerda (funcionarios) e os registros correspondentes do dataframe da direita (departamentos_)\nleft_join = pd.merge(\n  funcionarios, departamentos,  \n  how='left', \n  left_on='Departamento_ID', \n  right_on='ID_depto'\n)\n\nleft_join\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\nID_depto\nDepartamento\n\n\n\n\n0\n1\nJoão\n101\n101\nVendas\n\n\n1\n2\nMaria\n102\n102\nMarketing\n\n\n2\n3\nPedro\n101\n101\nVendas\n\n\n3\n4\nAna\n103\n103\nTI\n\n\n4\n5\nPaula\n102\n102\nMarketing\n\n\n\n\n\n\n\nO right funciona de maneira análoga, mas o B é a referência.\n\nJunção full outer join\n\nAqui, quermos juntar tudo. Quando não há correspondência (assim como em left e right), o Pandasretorna uma entrada nula.\n\n# Full Outer Join: retorna todos os registros quando há uma correspondência em um dos dataframes\nfull_outer_join = pd.merge(funcionarios, departamentos, how='outer', left_on='Departamento_ID', right_on='ID_depto')\nfull_outer_join\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\nID_depto\nDepartamento\n\n\n\n\n0\n1.0\nJoão\n101.0\n101\nVendas\n\n\n1\n3.0\nPedro\n101.0\n101\nVendas\n\n\n2\n2.0\nMaria\n102.0\n102\nMarketing\n\n\n3\n5.0\nPaula\n102.0\n102\nMarketing\n\n\n4\n4.0\nAna\n103.0\n103\nTI\n\n\n5\nNaN\nNaN\nNaN\n104\nRH\n\n\n\n\n\n\n\n\n\n\nÉ possível fazer a junção de mais de 2 dataframes que estejam relacionados entre si. Para isso, cada junção é salva em um novo dataframe (ou sobrescrita) até que se tenha o dataframe final.\n\n# Realizando a primeira junção entre dois dataframe:\njuncao_temporaria = pd.merge(df_A, df_B, how='inner', on='ID')\n\n# Realizando a segunda junção entre o resultado da primeira junção e um terceiro dataframe:\njuncao_final = pd.merge(juncao_temporaria, df_C, how='inner', on='ID')\n\n# Exibindo o DataFrame resultante da junção interna (inner join):\njuncao_final.head()"
  },
  {
    "objectID": "sections/juncoes.html#concatenação-com-o-método-concat",
    "href": "sections/juncoes.html#concatenação-com-o-método-concat",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Consideremos dois dataframes distintos que trazem preços de café em três determinadas lojas, nos dias 18/02/2024 e 19/02/2024, respectivamente.\n\nimport pandas as pd\n\nprecos_cafe_18022024 = pd.read_csv('dados/preco_cafes/precos_cafe_dia18.csv')\nprecos_cafe_19022024 = pd.read_csv('dados/preco_cafes/precos_cafe_dia19.csv')\n\n\nDia 18-02-204:\n\n\nprecos_cafe_18022024.head()\n\n\n\n\n\n\n\n\nData\nTipo_cafe\nPreco_loja_A\nPreco_loja_B\nPreco_loja_C\n\n\n\n\n0\n2024-02-18\nCafé Tradicional\n5.99\n6.49\n5.79\n\n\n1\n2024-02-18\nCafé Espresso\n3.49\n3.99\n3.29\n\n\n2\n2024-02-18\nCafé Descafeinado\n6.99\n7.49\n6.79\n\n\n\n\n\n\n\n\nDia 19-02-204:\n\n\nprecos_cafe_19022024.head()\n\n\n\n\n\n\n\n\nData\nTipo_cafe\nPreco_loja_A\nPreco_loja_B\nPreco_loja_C\n\n\n\n\n0\n2024-02-19\nCafé Tradicional\n5.89\n6.59\n5.69\n\n\n1\n2024-02-19\nCafé Espresso\n3.59\n4.09\n3.39\n\n\n2\n2024-02-19\nCafé Descafeinado\n6.79\n7.59\n6.89\n\n\n\n\n\n\n\nFrequentemente, precisamos consolidar dados, isto é, unificar esses dois ou mais dataframes, já que eles tratam do mesmo assunto. Isso facilita possíveis análises posteriores. Logo, podemos concatenar esses dataframes tanto na direção das linhas (axis=0) quanto na diração das colunas (axis=1), como mostra a Figura abaixo.\n\n\n\nConcatenação de dataframes\n\n\nNesse caso, fica nítido que a concatenação deve ocorrer no eixo das linhas. Isso pode ser feito da seguinte maneira:\n\n# pd.concat([df_1, df_2], axis=EIXO, ignore_index=True):\npreco_cafes = pd.concat(\n  [precos_cafe_18022024, precos_cafe_19022024], \n  axis=0, ignore_index=True\n)\n\n# visualizando o resultado:\npreco_cafes\n\n\n\n\n\n\n\n\nData\nTipo_cafe\nPreco_loja_A\nPreco_loja_B\nPreco_loja_C\n\n\n\n\n0\n2024-02-18\nCafé Tradicional\n5.99\n6.49\n5.79\n\n\n1\n2024-02-18\nCafé Espresso\n3.49\n3.99\n3.29\n\n\n2\n2024-02-18\nCafé Descafeinado\n6.99\n7.49\n6.79\n\n\n3\n2024-02-19\nCafé Tradicional\n5.89\n6.59\n5.69\n\n\n4\n2024-02-19\nCafé Espresso\n3.59\n4.09\n3.39\n\n\n5\n2024-02-19\nCafé Descafeinado\n6.79\n7.59\n6.89"
  },
  {
    "objectID": "sections/juncoes.html#junções-com-o-método-merge",
    "href": "sections/juncoes.html#junções-com-o-método-merge",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Basicamente, estes vários tipos de junções possíveis com este método - a Figura abaixo ilustra algumas.\n\n\n\nTipos de junções\n\n\nPara ilustrar os três primeiros casos (inner, left e right), criaremos dois dataframes para funcionários e dapartamentos.\nRegistro dos clientes (cadastro):\n\n# DataFrame de funcionários:\nfuncionarios = pd.DataFrame({\n    'ID_funcionario': [1, 2, 3, 4, 5],\n    'Nome': ['João', 'Maria', 'Pedro', 'Ana', 'Paula'],\n    'Departamento_ID': [101, 102, 101, 103, 102]\n})\n\nfuncionarios\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\n\n\n\n\n0\n1\nJoão\n101\n\n\n1\n2\nMaria\n102\n\n\n2\n3\nPedro\n101\n\n\n3\n4\nAna\n103\n\n\n4\n5\nPaula\n102\n\n\n\n\n\n\n\nRegistro dos departamentos:\n\n# DataFrame de departamentos:\ndepartamentos = pd.DataFrame({\n    'ID_depto': [101, 102, 103, 104],\n    'Departamento': ['Vendas', 'Marketing', 'TI', 'RH']\n})\n\ndepartamentos\n\n\n\n\n\n\n\n\nID_depto\nDepartamento\n\n\n\n\n0\n101\nVendas\n\n\n1\n102\nMarketing\n\n\n2\n103\nTI\n\n\n3\n104\nRH\n\n\n\n\n\n\n\n\nJunção inner join\n\nNesse caso queremos a intersecção entre os dataframes A e B, isto é, aquilo que é comum a ambos apenas.\n\n# Inner Join: retorna apenas os registros comuns aos dois dataframes\ninner_join = pd.merge(\n  funcionarios, departamentos, \n  how='inner', \n  left_on='Departamento_ID', \n  right_on='ID_depto'\n)\n\ninner_join\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\nID_depto\nDepartamento\n\n\n\n\n0\n1\nJoão\n101\n101\nVendas\n\n\n1\n3\nPedro\n101\n101\nVendas\n\n\n2\n2\nMaria\n102\n102\nMarketing\n\n\n3\n5\nPaula\n102\n102\nMarketing\n\n\n4\n4\nAna\n103\n103\nTI\n\n\n\n\n\n\n\n\nJunção left join/right join\n\nNeste caso, desejamos obter os dados de A mais a interseção de A e B (todo os dados de A, mais o que há de comum entre A e B) - no left.\n\n# Left Join: retorna todos os registros do dataframe da esquerda (funcionarios) e os registros correspondentes do dataframe da direita (departamentos_)\nleft_join = pd.merge(\n  funcionarios, departamentos,  \n  how='left', \n  left_on='Departamento_ID', \n  right_on='ID_depto'\n)\n\nleft_join\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\nID_depto\nDepartamento\n\n\n\n\n0\n1\nJoão\n101\n101\nVendas\n\n\n1\n2\nMaria\n102\n102\nMarketing\n\n\n2\n3\nPedro\n101\n101\nVendas\n\n\n3\n4\nAna\n103\n103\nTI\n\n\n4\n5\nPaula\n102\n102\nMarketing\n\n\n\n\n\n\n\nO right funciona de maneira análoga, mas o B é a referência.\n\nJunção full outer join\n\nAqui, quermos juntar tudo. Quando não há correspondência (assim como em left e right), o Pandasretorna uma entrada nula.\n\n# Full Outer Join: retorna todos os registros quando há uma correspondência em um dos dataframes\nfull_outer_join = pd.merge(funcionarios, departamentos, how='outer', left_on='Departamento_ID', right_on='ID_depto')\nfull_outer_join\n\n\n\n\n\n\n\n\nID_funcionario\nNome\nDepartamento_ID\nID_depto\nDepartamento\n\n\n\n\n0\n1.0\nJoão\n101.0\n101\nVendas\n\n\n1\n3.0\nPedro\n101.0\n101\nVendas\n\n\n2\n2.0\nMaria\n102.0\n102\nMarketing\n\n\n3\n5.0\nPaula\n102.0\n102\nMarketing\n\n\n4\n4.0\nAna\n103.0\n103\nTI\n\n\n5\nNaN\nNaN\nNaN\n104\nRH\n\n\n\n\n\n\n\n\n\n\nÉ possível fazer a junção de mais de 2 dataframes que estejam relacionados entre si. Para isso, cada junção é salva em um novo dataframe (ou sobrescrita) até que se tenha o dataframe final.\n\n# Realizando a primeira junção entre dois dataframe:\njuncao_temporaria = pd.merge(df_A, df_B, how='inner', on='ID')\n\n# Realizando a segunda junção entre o resultado da primeira junção e um terceiro dataframe:\njuncao_final = pd.merge(juncao_temporaria, df_C, how='inner', on='ID')\n\n# Exibindo o DataFrame resultante da junção interna (inner join):\njuncao_final.head()"
  },
  {
    "objectID": "sections/limpeza_de_dados.html",
    "href": "sections/limpeza_de_dados.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesta aula, vamos trabalhar com métodos aplicáveis à limpeza de dados com Pandas. Veremos os métodos para:\n\nRenomear colunas\nFormatar textos (minúsculo, maísculo, primeira letra em maiúscula)\nRealizar substituições com o método .replace()\nTratar nulos - método .fillna()\nConverter tipos de dados em um dataframe\nCriar funções anônimas - função lambda e método .apply().\n\nEsses tópicos são fundamentais em processos de ETL (Extract, Transform and Load) em projetos envolvendo dados. Ao longo desse módulos, vamos trabalhar com o conjunto de dados `` que trata de clientes da CifraOnline, um banco digital fictício com 1000 linhas.\n\nimport pandas as pd\n\nclientes_cifraonline = pd.read_csv('dados/clientes-banco-cifraonline/clientes_cifraonline.csv')\n\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\nsexo\nsalario\ncidade\nstatus_emprego\nnivel_educacional\nscore_credito\n\n\n\n\n0\nJoão\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nMariano\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n2\nLuiz\n71\nM\nR$ 6545\nRio de Janeiro\nAutônomo\nGraduação\n438\n\n\n3\nPaula\n18\nF\nR$ 3896\nSalvador\nEmpregado\nEnsino Médio\n831\n\n\n4\nCarlo\n21\nM\nR$ 12383\nSalvador\nAutônomo\nGraduação\n384\n\n\n\n\n\n\n\nAntes de inicar os tópicos, é importante notarmos que temos, dentre outras particularidades:\n\nDados numéricos configurados como texto (coluna salario)\nNomes despadronizados quanto à formatação (coluna nome).\n\n\nclientes_cifraonline.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   nome               1000 non-null   object\n 1   idade              1000 non-null   int64 \n 2   sexo               1000 non-null   object\n 3   salario            1000 non-null   object\n 4   cidade             1000 non-null   object\n 5   status_emprego     1000 non-null   object\n 6   nivel_educacional  1000 non-null   object\n 7   score_credito      1000 non-null   int64 \ndtypes: int64(2), object(6)\nmemory usage: 62.6+ KB\n\n\n\n\nPara renomear colunas em um dataframe, podemos utilizar o método rename, ilustrado abaixo.\ndados = dados.rename(columns={'coluna original': 'coluna renomeada'})\nVejamos na prática:\n\n# Alterando nome de duas colunas:\nclientes_cifraonline = clientes_cifraonline.rename(\n    columns = {'nivel_educacional': 'formacao', 'sexo': 'genero'}\n)\n\n# Visualizando os resultados:\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\nJoão\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nMariano\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n2\nLuiz\n71\nM\nR$ 6545\nRio de Janeiro\nAutônomo\nGraduação\n438\n\n\n3\nPaula\n18\nF\nR$ 3896\nSalvador\nEmpregado\nEnsino Médio\n831\n\n\n4\nCarlo\n21\nM\nR$ 12383\nSalvador\nAutônomo\nGraduação\n384\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCaso desejemos eliminar colunas, podemos utilizar:\ndados.drop(['coluna A'], axis=1, inplace=True)\n\n\n\n\n\nNo conjunto de dados em questão, também temos nomes despadronizados (ora letras maiúsculas, ora minúsculas). Podemos lidar com esse tipo de situação (ver coluna nome) utilizando:\n\n# Texto em minúsculo:\nclientes_cifraonline['nome'] = clientes_cifraonline['nome'].str.lower()\nclientes_cifraonline.head(2)\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\njoão\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nmariano\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n\n\n\n\n\n\n# Texto em maiúsculo:\nclientes_cifraonline['nome'] = clientes_cifraonline['nome'].str.upper()\nclientes_cifraonline.head(2)\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\nJOÃO\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nMARIANO\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n\n\n\n\n\n\n# Texto com Primeira Letra em Maiúsculo:\nclientes_cifraonline['nome'] = clientes_cifraonline['nome'].str.title()\nclientes_cifraonline.head(2)\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\nJoão\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nMariano\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n\n\n\n\n\n\n\n\nFrequentemente, vamos precisar substituir valores em um dataframe. Para isso, podemos utilizar o método .replace() conforme procede abaixo:\n# Subsitutuição em todo o dataframe:\ndados = dados.replace('Valor original', 'Valor substituído')\n\n# Substituição em uma coluna específica:\ndados['coluna A'] = dados['coluna A'].replace('Valor original', 'Valor substituído')\n\n# Também funciona com números:\ndados['coluna A'] = dados['coluna A'].replace(0, 50)\nNo nosso caso, vamos adicionar alguns dados nulos em nosso dataframe com o auxílio da biblioteca numpy. Além disso, vamos criar uma variável numérica para genero, onde:\n\nAos clientes do gênero Feminino (F) será atribuídos o valor 0\nAos clientes do gênero Masculino (M) será atribuídos o valor 1\n\n\n# Biblioteca numpy:\nimport numpy as np\n\n# Adicionando nulos:\nclientes_cifraonline['score_credito'] = clientes_cifraonline['score_credito'].replace(793, np.nan).replace(831, np.nan).replace(719, np.nan)\n# Visualização dos resultados\nclientes_cifraonline.isna().sum()/len(clientes_cifraonline)*100\n\nnome              0.0\nidade             0.0\ngenero            0.0\nsalario           0.0\ncidade            0.0\nstatus_emprego    0.0\nformacao          0.0\nscore_credito     0.7\ndtype: float64\n\n\n\nNote que temos 0,7% de nulos no conjunto de dados agora.\n\n\n# Codigicando a coluna gênero:\nclientes_cifraonline['genero_cod'] = clientes_cifraonline['genero'] # cópia da original\n# Outra opção é usar o `inplace`:\nclientes_cifraonline['genero_cod'].replace('F', 0, inplace=True)\nclientes_cifraonline['genero_cod'].replace('M', 1, inplace=True)\n\n# Visualização dos resultados:\nclientes_cifraonline[['nome', 'genero', 'genero_cod']].head(10)\n\n\n\n\n\n\n\n\nnome\ngenero\ngenero_cod\n\n\n\n\n0\nJoão\nM\n1\n\n\n1\nMariano\nM\n1\n\n\n2\nLuiz\nM\n1\n\n\n3\nPaula\nF\n0\n\n\n4\nCarlo\nM\n1\n\n\n5\nLuiz\nM\n1\n\n\n6\nFelipe\nM\n1\n\n\n7\nAna\nF\n0\n\n\n8\nPaula\nF\n0\n\n\n9\nPaulo\nM\n1\n\n\n\n\n\n\n\n\n\n\nPara o tratamento de nulos, poderímos usar algumas ténicas com o método .fillna().\n# Preenchimento com 'zero':\ndados['coluna A'] = dados['coluna A'].fillna(0)\n\n# Preenchimento com a média:\nmedia_coluna_A = dados['Salário'].mean()\ndados['coluna A'] = dados['coluna A'].fillna(media_coluna_A)\n\n# Preenchimento com a mediana:\nmediana_coluna_A = dados['Salário'].median()\ndados['coluna A'] = dados['coluna A'].fillna(mediana_coluna_A)\n\n# Preenchimento com a moda:\nmoda_coluna_A = dados['Salário'].mode()\ndados['coluna A'] = dados['coluna A'].fillna(moda_coluna_A)\n\n# Preenchimento com a texto:\ndados['coluna A'] = dados['coluna A'].fillna('Não informado')\n\n\n\n\n\n\nTip\n\n\n\nNote que também poderíamos preencher nulos utilizando algoritmos de Machine Learning (e.g., K-Nearest Neighbors, Random Forest, IterativeImputer, etc.). Entretando, esse assunto foge do escopo desse curso e não iremos abordá-lo.\n\n\nComo nesse caso os nulos representam apenas 0,7% do conjunto de dados, podemos apenas eliminar essas linhas.\n\n# Total de linhas (originalmente):\nprint(f'Total de linhas antes da remoçao de nulos: {clientes_cifraonline.shape[0]}')\n\n# Remoção de nulos:\nclientes_cifraonline.dropna(axis=0, inplace=True)\n# Impacto:\nprint(f'Total de linhas após a remoçao de nulos: {clientes_cifraonline.shape[0]}')\n\nTotal de linhas antes da remoçao de nulos: 1000\nTotal de linhas após a remoçao de nulos: 993\n\n\n\n\n\nNo conjunto de dados em questão, notamos que a coluna salario está marcada como objeto. Isso se dá pois temos os caracteres ‘R$’, responsáveis por classificar a coluna salário como string. Para tratar essa coluna e obter valores numéricos, precisamos:\n\nRemover caracteres especiais\nVerificar separador decimal (se necessário, trocamos vírgula por ponto)\nConverter o tipo de dado (object \\(\\rightarrow\\) int) - métodos pd.to_numeric() e .astype().\n\nMétodos:\n# método 1:\ndados['coluna A'] = pd.to_numeric(dados['coluna A'], errors='coerce')\n\n# método 2:\ndados['coluna A'] = dados['coluna A'].astype('float64')\nNa prática, temos:\n\n# Removendo o prefixo 'R$' e os caracteres '.0' da coluna 'salario':\nclientes_cifraonline['salario'] = clientes_cifraonline['salario'].str.replace('R$', '')\n\n# Convertendo o tipo de dado para numérico, ignorando erros para lidar com valores não numéricos:\nclientes_cifraonline['salario'] = pd.to_numeric(clientes_cifraonline['salario'], errors='coerce')\n\n# Podemos converter esse inteiro para float:\nclientes_cifraonline['salario'] = clientes_cifraonline['salario'].astype('float64')\n\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\ngenero_cod\n\n\n\n\n1\nMariano\n65\nM\n7000.0\nPorto Alegre\nAutônomo\nPós-graduação\n626.0\n1\n\n\n2\nLuiz\n71\nM\n6545.0\nRio de Janeiro\nAutônomo\nGraduação\n438.0\n1\n\n\n4\nCarlo\n21\nM\n12383.0\nSalvador\nAutônomo\nGraduação\n384.0\n1\n\n\n5\nLuiz\n77\nM\n1823.0\nPorto Alegre\nAutônomo\nEnsino Médio\n737.0\n1\n\n\n6\nFelipe\n21\nM\n1490.0\nPorto Alegre\nAutônomo\nEnsino Médio\n482.0\n1\n\n\n\n\n\n\n\nDa mesma maneira, score poderia ser um inteiro:\n\n# Conversão:\nclientes_cifraonline['score_credito'] = clientes_cifraonline['score_credito'].astype('int64')\n\n# Resultado:\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\ngenero_cod\n\n\n\n\n1\nMariano\n65\nM\n7000.0\nPorto Alegre\nAutônomo\nPós-graduação\n626\n1\n\n\n2\nLuiz\n71\nM\n6545.0\nRio de Janeiro\nAutônomo\nGraduação\n438\n1\n\n\n4\nCarlo\n21\nM\n12383.0\nSalvador\nAutônomo\nGraduação\n384\n1\n\n\n5\nLuiz\n77\nM\n1823.0\nPorto Alegre\nAutônomo\nEnsino Médio\n737\n1\n\n\n6\nFelipe\n21\nM\n1490.0\nPorto Alegre\nAutônomo\nEnsino Médio\n482\n1\n\n\n\n\n\n\n\n\n\n\nOutra possilibdade é a utilização de funções anônimas - famosa função lambda. A sintaxe é dada por:\n(lambda &lt;variavel(eis)&gt;: &lt;expressao&gt;)\nVamos supor que desejamos anualizar o salários do clientes, logo poderíamos aplicar uma função lambda:\n\n# Cópia de `salario`:\nclientes_cifraonline['salario_anual'] = clientes_cifraonline['salario']\n\n# Anualizando `salario`:\nclientes_cifraonline['salario_anual'] = clientes_cifraonline['salario_anual'].apply(lambda salario: salario * 12)\n\nclientes_cifraonline[['salario', 'salario_anual']].head()\n\n\n\n\n\n\n\n\nsalario\nsalario_anual\n\n\n\n\n1\n7000.0\n84000.0\n\n\n2\n6545.0\n78540.0\n\n\n4\n12383.0\n148596.0\n\n\n5\n1823.0\n21876.0\n\n\n6\n1490.0\n17880.0\n\n\n\n\n\n\n\nNo caso da codificação do gênero, também poderia ser feita com uma função anônima:\n\n# Codificação utilizando função anônima:\nclientes_cifraonline['genero_cod_lambda'] = clientes_cifraonline['genero'].apply(lambda registro: \n    0 if registro == 'F' else 1\n)\n\n# Resultado:\nclientes_cifraonline[['genero', 'genero_cod_lambda']].tail()\n\n\n\n\n\n\n\n\ngenero\ngenero_cod_lambda\n\n\n\n\n994\nF\n0\n\n\n995\nM\n1\n\n\n996\nF\n0\n\n\n998\nF\n0\n\n\n999\nM\n1\n\n\n\n\n\n\n\nPodemos também criar funções previamente definias e aplicar ao conjunto de dados utilizando o método .apply().\n\n# Função para categorizar score de crédito\ndef categorizar_score(score):\n    if score &lt; 500:\n        return 'Baixo'\n    elif score &lt; 700:\n        return 'Médio'\n    else:\n        return 'Alto'\n\n# Aplicar a função categorizar_score à coluna 'score_credito'\nclientes_cifraonline['faixa_score'] = clientes_cifraonline['score_credito'].apply(categorizar_score)\n\n# Resultado:\nclientes_cifraonline[['nome','genero','salario','score_credito','faixa_score']].head()\n\n\n\n\n\n\n\n\nnome\ngenero\nsalario\nscore_credito\nfaixa_score\n\n\n\n\n1\nMariano\nM\n7000.0\n626\nMédio\n\n\n2\nLuiz\nM\n6545.0\n438\nBaixo\n\n\n4\nCarlo\nM\n12383.0\n384\nBaixo\n\n\n5\nLuiz\nM\n1823.0\n737\nAlto\n\n\n6\nFelipe\nM\n1490.0\n482\nBaixo"
  },
  {
    "objectID": "sections/limpeza_de_dados.html#renomear-colunas",
    "href": "sections/limpeza_de_dados.html#renomear-colunas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Para renomear colunas em um dataframe, podemos utilizar o método rename, ilustrado abaixo.\ndados = dados.rename(columns={'coluna original': 'coluna renomeada'})\nVejamos na prática:\n\n# Alterando nome de duas colunas:\nclientes_cifraonline = clientes_cifraonline.rename(\n    columns = {'nivel_educacional': 'formacao', 'sexo': 'genero'}\n)\n\n# Visualizando os resultados:\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\nJoão\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nMariano\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n2\nLuiz\n71\nM\nR$ 6545\nRio de Janeiro\nAutônomo\nGraduação\n438\n\n\n3\nPaula\n18\nF\nR$ 3896\nSalvador\nEmpregado\nEnsino Médio\n831\n\n\n4\nCarlo\n21\nM\nR$ 12383\nSalvador\nAutônomo\nGraduação\n384\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCaso desejemos eliminar colunas, podemos utilizar:\ndados.drop(['coluna A'], axis=1, inplace=True)"
  },
  {
    "objectID": "sections/limpeza_de_dados.html#formatar-textos",
    "href": "sections/limpeza_de_dados.html#formatar-textos",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "No conjunto de dados em questão, também temos nomes despadronizados (ora letras maiúsculas, ora minúsculas). Podemos lidar com esse tipo de situação (ver coluna nome) utilizando:\n\n# Texto em minúsculo:\nclientes_cifraonline['nome'] = clientes_cifraonline['nome'].str.lower()\nclientes_cifraonline.head(2)\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\njoão\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nmariano\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n\n\n\n\n\n\n# Texto em maiúsculo:\nclientes_cifraonline['nome'] = clientes_cifraonline['nome'].str.upper()\nclientes_cifraonline.head(2)\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\nJOÃO\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nMARIANO\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626\n\n\n\n\n\n\n\n\n# Texto com Primeira Letra em Maiúsculo:\nclientes_cifraonline['nome'] = clientes_cifraonline['nome'].str.title()\nclientes_cifraonline.head(2)\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\n\n\n\n\n0\nJoão\n62\nM\nR$ 6728\nSão Paulo\nDesempregado\nMestrado\n793\n\n\n1\nMariano\n65\nM\nR$ 7000\nPorto Alegre\nAutônomo\nPós-graduação\n626"
  },
  {
    "objectID": "sections/limpeza_de_dados.html#substituições",
    "href": "sections/limpeza_de_dados.html#substituições",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Frequentemente, vamos precisar substituir valores em um dataframe. Para isso, podemos utilizar o método .replace() conforme procede abaixo:\n# Subsitutuição em todo o dataframe:\ndados = dados.replace('Valor original', 'Valor substituído')\n\n# Substituição em uma coluna específica:\ndados['coluna A'] = dados['coluna A'].replace('Valor original', 'Valor substituído')\n\n# Também funciona com números:\ndados['coluna A'] = dados['coluna A'].replace(0, 50)\nNo nosso caso, vamos adicionar alguns dados nulos em nosso dataframe com o auxílio da biblioteca numpy. Além disso, vamos criar uma variável numérica para genero, onde:\n\nAos clientes do gênero Feminino (F) será atribuídos o valor 0\nAos clientes do gênero Masculino (M) será atribuídos o valor 1\n\n\n# Biblioteca numpy:\nimport numpy as np\n\n# Adicionando nulos:\nclientes_cifraonline['score_credito'] = clientes_cifraonline['score_credito'].replace(793, np.nan).replace(831, np.nan).replace(719, np.nan)\n# Visualização dos resultados\nclientes_cifraonline.isna().sum()/len(clientes_cifraonline)*100\n\nnome              0.0\nidade             0.0\ngenero            0.0\nsalario           0.0\ncidade            0.0\nstatus_emprego    0.0\nformacao          0.0\nscore_credito     0.7\ndtype: float64\n\n\n\nNote que temos 0,7% de nulos no conjunto de dados agora.\n\n\n# Codigicando a coluna gênero:\nclientes_cifraonline['genero_cod'] = clientes_cifraonline['genero'] # cópia da original\n# Outra opção é usar o `inplace`:\nclientes_cifraonline['genero_cod'].replace('F', 0, inplace=True)\nclientes_cifraonline['genero_cod'].replace('M', 1, inplace=True)\n\n# Visualização dos resultados:\nclientes_cifraonline[['nome', 'genero', 'genero_cod']].head(10)\n\n\n\n\n\n\n\n\nnome\ngenero\ngenero_cod\n\n\n\n\n0\nJoão\nM\n1\n\n\n1\nMariano\nM\n1\n\n\n2\nLuiz\nM\n1\n\n\n3\nPaula\nF\n0\n\n\n4\nCarlo\nM\n1\n\n\n5\nLuiz\nM\n1\n\n\n6\nFelipe\nM\n1\n\n\n7\nAna\nF\n0\n\n\n8\nPaula\nF\n0\n\n\n9\nPaulo\nM\n1"
  },
  {
    "objectID": "sections/limpeza_de_dados.html#tratar-nulos",
    "href": "sections/limpeza_de_dados.html#tratar-nulos",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Para o tratamento de nulos, poderímos usar algumas ténicas com o método .fillna().\n# Preenchimento com 'zero':\ndados['coluna A'] = dados['coluna A'].fillna(0)\n\n# Preenchimento com a média:\nmedia_coluna_A = dados['Salário'].mean()\ndados['coluna A'] = dados['coluna A'].fillna(media_coluna_A)\n\n# Preenchimento com a mediana:\nmediana_coluna_A = dados['Salário'].median()\ndados['coluna A'] = dados['coluna A'].fillna(mediana_coluna_A)\n\n# Preenchimento com a moda:\nmoda_coluna_A = dados['Salário'].mode()\ndados['coluna A'] = dados['coluna A'].fillna(moda_coluna_A)\n\n# Preenchimento com a texto:\ndados['coluna A'] = dados['coluna A'].fillna('Não informado')\n\n\n\n\n\n\nTip\n\n\n\nNote que também poderíamos preencher nulos utilizando algoritmos de Machine Learning (e.g., K-Nearest Neighbors, Random Forest, IterativeImputer, etc.). Entretando, esse assunto foge do escopo desse curso e não iremos abordá-lo.\n\n\nComo nesse caso os nulos representam apenas 0,7% do conjunto de dados, podemos apenas eliminar essas linhas.\n\n# Total de linhas (originalmente):\nprint(f'Total de linhas antes da remoçao de nulos: {clientes_cifraonline.shape[0]}')\n\n# Remoção de nulos:\nclientes_cifraonline.dropna(axis=0, inplace=True)\n# Impacto:\nprint(f'Total de linhas após a remoçao de nulos: {clientes_cifraonline.shape[0]}')\n\nTotal de linhas antes da remoçao de nulos: 1000\nTotal de linhas após a remoçao de nulos: 993"
  },
  {
    "objectID": "sections/limpeza_de_dados.html#converter-tipos-de-dados",
    "href": "sections/limpeza_de_dados.html#converter-tipos-de-dados",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "No conjunto de dados em questão, notamos que a coluna salario está marcada como objeto. Isso se dá pois temos os caracteres ‘R$’, responsáveis por classificar a coluna salário como string. Para tratar essa coluna e obter valores numéricos, precisamos:\n\nRemover caracteres especiais\nVerificar separador decimal (se necessário, trocamos vírgula por ponto)\nConverter o tipo de dado (object \\(\\rightarrow\\) int) - métodos pd.to_numeric() e .astype().\n\nMétodos:\n# método 1:\ndados['coluna A'] = pd.to_numeric(dados['coluna A'], errors='coerce')\n\n# método 2:\ndados['coluna A'] = dados['coluna A'].astype('float64')\nNa prática, temos:\n\n# Removendo o prefixo 'R$' e os caracteres '.0' da coluna 'salario':\nclientes_cifraonline['salario'] = clientes_cifraonline['salario'].str.replace('R$', '')\n\n# Convertendo o tipo de dado para numérico, ignorando erros para lidar com valores não numéricos:\nclientes_cifraonline['salario'] = pd.to_numeric(clientes_cifraonline['salario'], errors='coerce')\n\n# Podemos converter esse inteiro para float:\nclientes_cifraonline['salario'] = clientes_cifraonline['salario'].astype('float64')\n\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\ngenero_cod\n\n\n\n\n1\nMariano\n65\nM\n7000.0\nPorto Alegre\nAutônomo\nPós-graduação\n626.0\n1\n\n\n2\nLuiz\n71\nM\n6545.0\nRio de Janeiro\nAutônomo\nGraduação\n438.0\n1\n\n\n4\nCarlo\n21\nM\n12383.0\nSalvador\nAutônomo\nGraduação\n384.0\n1\n\n\n5\nLuiz\n77\nM\n1823.0\nPorto Alegre\nAutônomo\nEnsino Médio\n737.0\n1\n\n\n6\nFelipe\n21\nM\n1490.0\nPorto Alegre\nAutônomo\nEnsino Médio\n482.0\n1\n\n\n\n\n\n\n\nDa mesma maneira, score poderia ser um inteiro:\n\n# Conversão:\nclientes_cifraonline['score_credito'] = clientes_cifraonline['score_credito'].astype('int64')\n\n# Resultado:\nclientes_cifraonline.head()\n\n\n\n\n\n\n\n\nnome\nidade\ngenero\nsalario\ncidade\nstatus_emprego\nformacao\nscore_credito\ngenero_cod\n\n\n\n\n1\nMariano\n65\nM\n7000.0\nPorto Alegre\nAutônomo\nPós-graduação\n626\n1\n\n\n2\nLuiz\n71\nM\n6545.0\nRio de Janeiro\nAutônomo\nGraduação\n438\n1\n\n\n4\nCarlo\n21\nM\n12383.0\nSalvador\nAutônomo\nGraduação\n384\n1\n\n\n5\nLuiz\n77\nM\n1823.0\nPorto Alegre\nAutônomo\nEnsino Médio\n737\n1\n\n\n6\nFelipe\n21\nM\n1490.0\nPorto Alegre\nAutônomo\nEnsino Médio\n482\n1"
  },
  {
    "objectID": "sections/limpeza_de_dados.html#funções-anônimas",
    "href": "sections/limpeza_de_dados.html#funções-anônimas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Outra possilibdade é a utilização de funções anônimas - famosa função lambda. A sintaxe é dada por:\n(lambda &lt;variavel(eis)&gt;: &lt;expressao&gt;)\nVamos supor que desejamos anualizar o salários do clientes, logo poderíamos aplicar uma função lambda:\n\n# Cópia de `salario`:\nclientes_cifraonline['salario_anual'] = clientes_cifraonline['salario']\n\n# Anualizando `salario`:\nclientes_cifraonline['salario_anual'] = clientes_cifraonline['salario_anual'].apply(lambda salario: salario * 12)\n\nclientes_cifraonline[['salario', 'salario_anual']].head()\n\n\n\n\n\n\n\n\nsalario\nsalario_anual\n\n\n\n\n1\n7000.0\n84000.0\n\n\n2\n6545.0\n78540.0\n\n\n4\n12383.0\n148596.0\n\n\n5\n1823.0\n21876.0\n\n\n6\n1490.0\n17880.0\n\n\n\n\n\n\n\nNo caso da codificação do gênero, também poderia ser feita com uma função anônima:\n\n# Codificação utilizando função anônima:\nclientes_cifraonline['genero_cod_lambda'] = clientes_cifraonline['genero'].apply(lambda registro: \n    0 if registro == 'F' else 1\n)\n\n# Resultado:\nclientes_cifraonline[['genero', 'genero_cod_lambda']].tail()\n\n\n\n\n\n\n\n\ngenero\ngenero_cod_lambda\n\n\n\n\n994\nF\n0\n\n\n995\nM\n1\n\n\n996\nF\n0\n\n\n998\nF\n0\n\n\n999\nM\n1\n\n\n\n\n\n\n\nPodemos também criar funções previamente definias e aplicar ao conjunto de dados utilizando o método .apply().\n\n# Função para categorizar score de crédito\ndef categorizar_score(score):\n    if score &lt; 500:\n        return 'Baixo'\n    elif score &lt; 700:\n        return 'Médio'\n    else:\n        return 'Alto'\n\n# Aplicar a função categorizar_score à coluna 'score_credito'\nclientes_cifraonline['faixa_score'] = clientes_cifraonline['score_credito'].apply(categorizar_score)\n\n# Resultado:\nclientes_cifraonline[['nome','genero','salario','score_credito','faixa_score']].head()\n\n\n\n\n\n\n\n\nnome\ngenero\nsalario\nscore_credito\nfaixa_score\n\n\n\n\n1\nMariano\nM\n7000.0\n626\nMédio\n\n\n2\nLuiz\nM\n6545.0\n438\nBaixo\n\n\n4\nCarlo\nM\n12383.0\n384\nBaixo\n\n\n5\nLuiz\nM\n1823.0\n737\nAlto\n\n\n6\nFelipe\nM\n1490.0\n482\nBaixo"
  },
  {
    "objectID": "sections/slicing_e_filtros.html",
    "href": "sections/slicing_e_filtros.html",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Nesta aula, vamos trabalhar com um conjunto de dados sobre o preço dos serviços de streaming. Veremos alguns métodos pandas para:\n\nSelecionar colunas\nEliminar colunas\nRealizar slicing (linhas, colunas)\nRealizar slicing lógico (condições)\nRealizar consultas SQL\nAplicar outros filtros de colunas\n\nAntes, precisamos importar a biblioteca e carregar os dados.\n\nimport pandas as pd\n\npreco_streamings = pd.read_excel('dados/preco_servicos_streaming/Streaming_prices.xlsx')\npreco_streamings.head(2)\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n\n\n\n\n\n\n\nUma maneira simples de selecionar colunas é especificar quais colunas se quer filtrar utilizando colchetes duplos ([['coluna A', 'coluna B', 'coluna N']]).\n\npreco_streamings[['Streaming service', 'Price (USD)']]\n\n\n\n\n\n\n\n\nStreaming service\nPrice (USD)\n\n\n\n\n0\nNetflix\n7.99\n\n\n1\nNetflix\n7.99\n\n\n2\nNetflix\n7.99\n\n\n3\nNetflix\n7.99\n\n\n4\nNetflix\n7.99\n\n\n...\n...\n...\n\n\n499\nApple TV+\n6.99\n\n\n500\nApple TV+\n6.99\n\n\n501\nApple TV+\n6.99\n\n\n502\nApple TV+\n6.99\n\n\n503\nApple TV+\n9.99\n\n\n\n\n504 rows × 2 columns\n\n\n\nInclusive, é possível salvar essa seleção em outro dataframe (ou variável): `\n\nstreaming_e_preco = preco_streamings[['Streaming service', 'Price (USD)']]\nstreaming_e_preco.tail(3)\n\n\n\n\n\n\n\n\nStreaming service\nPrice (USD)\n\n\n\n\n501\nApple TV+\n6.99\n\n\n502\nApple TV+\n6.99\n\n\n503\nApple TV+\n9.99\n\n\n\n\n\n\n\n\n\n\nVamos supor que eu queria trabalhar apenas com a lista de streamings disponíveis no dataset. Uma maneira de fazer isso é:\n\nListar as duplicatas de Streaming service\nEliminar as demais colunas.\n\nPara isso, podemos usar os métodos .drop_duplicates() e o método .drop() - este último tem como opções indicar o eixo (0: linhas, 1: colunas) e o paramêtro inplace=True, que permite sobreescrever o dataframe.\n\n# Listando os serviços de streaming (sem duplicatas) e as demais colunas:\nstreamings = preco_streamings.drop_duplicates(subset='Streaming service')\n\n# Elimiando as colunas de data e preço:\nstreamings.drop(['Reference date', 'Price (USD)'], axis=1, inplace=True)\nstreamings\n\n\n\n\n\n\n\n\nStreaming service\n\n\n\n\n0\nNetflix\n\n\n151\nDisney+\n\n\n202\nHBO Max\n\n\n247\nParamount+\n\n\n359\nPrime Video\n\n\n453\nApple TV+\n\n\n\n\n\n\n\n\n\n\nOs métodos mencionados no título da seção são muito eficazes e permitem selecionar linhas e também a combinação de linhas e colunas.\n# loc (selecionar linhas)\ndf.loc[i]\n\n# iloc (selecionar linhas e colunas)\ndf.iloc[i,j]\nPara melhor entendimento, vejamos alguns exemploa:\n\nLinha 20 (lembre que os índices começam em 0)\n\n\npreco_streamings.loc[19]\n\nStreaming service     Netflix\nReference date       Feb-2013\nPrice (USD)              7.99\nName: 19, dtype: object\n\n\n\nÍndices 400-405\n\n\n# linha 20 (lembre que os índices começam em 0)\npreco_streamings.loc[400:405]\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n400\nPrime Video\nSep-2019\n8.99\n\n\n401\nPrime Video\nOct-2019\n8.99\n\n\n402\nPrime Video\nNov-2019\n8.99\n\n\n403\nPrime Video\nDec-2019\n8.99\n\n\n404\nPrime Video\nJan-2020\n8.99\n\n\n405\nPrime Video\nFeb-2020\n8.99\n\n\n\n\n\n\n\n\nLinhas e colunas\n\n\n# indices 10:14 (10, n-1) e coluna 3 (preço):\npreco_streamings.iloc[10:16, 2]\n\n10    7.99\n11    7.99\n12    7.99\n13    7.99\n14    7.99\n15    7.99\nName: Price (USD), dtype: float64\n\n\n\n\n\nPodemos aplicar condições durante o slicing em um dataframe.\n\n# condição:\ncondicao = preco_streamings['Streaming service'] == 'Prime Video'\n\n# slicing (apenas Prime Video):\npreco_streamings[condicao]\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n359\nPrime Video\nApr-2016\n8.99\n\n\n360\nPrime Video\nMay-2016\n8.99\n\n\n361\nPrime Video\nJun-2016\n8.99\n\n\n362\nPrime Video\nJul-2016\n8.99\n\n\n363\nPrime Video\nAug-2016\n8.99\n\n\n...\n...\n...\n...\n\n\n448\nPrime Video\nSep-2023\n8.99\n\n\n449\nPrime Video\nOct-2023\n8.99\n\n\n450\nPrime Video\nNov-2023\n8.99\n\n\n451\nPrime Video\nDec-2023\n8.99\n\n\n452\nPrime Video\nJan-2024\n11.99\n\n\n\n\n94 rows × 3 columns\n\n\n\nCertamente, isso pode ser realizado em uma única linha de código também:\n\n# slicing (todos os streamings menos Prime Video):\npreco_streamings[preco_streamings['Streaming service'] != 'Prime Video']\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n499\nApple TV+\nSep-2023\n6.99\n\n\n500\nApple TV+\nOct-2023\n6.99\n\n\n501\nApple TV+\nNov-2023\n6.99\n\n\n502\nApple TV+\nDec-2023\n6.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n410 rows × 3 columns\n\n\n\nOutro exemplo seria:\n\n# condição:\ncondicao_A = preco_streamings['Streaming service'] == 'Prime Video' \ncondicao_B = preco_streamings['Streaming service'] == 'Disney+'\n\n# slicing (streamings: Prime Video ou Disney+ ):\npreco_streamings[condicao_A | condicao_B]\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n151\nDisney+\nNov-2019\n6.99\n\n\n152\nDisney+\nDec-2019\n6.99\n\n\n153\nDisney+\nJan-2020\n6.99\n\n\n154\nDisney+\nFeb-2020\n6.99\n\n\n155\nDisney+\nMar-2020\n6.99\n\n\n...\n...\n...\n...\n\n\n448\nPrime Video\nSep-2023\n8.99\n\n\n449\nPrime Video\nOct-2023\n8.99\n\n\n450\nPrime Video\nNov-2023\n8.99\n\n\n451\nPrime Video\nDec-2023\n8.99\n\n\n452\nPrime Video\nJan-2024\n11.99\n\n\n\n\n145 rows × 3 columns\n\n\n\n\n\n\nPodemos utilizar de expressões muito similares a linguagem SQL.\n#query\ndf.query(&lt;expressão&gt;)\nVejamos alguns exemplos que ilustram as possibilidades desse método.\n\npreco_streamings.query(' `Price (USD)` &gt;= 7.99 & `Price (USD)` &lt; 11.99')\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n448\nPrime Video\nSep-2023\n8.99\n\n\n449\nPrime Video\nOct-2023\n8.99\n\n\n450\nPrime Video\nNov-2023\n8.99\n\n\n451\nPrime Video\nDec-2023\n8.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n376 rows × 3 columns\n\n\n\n\npreco_streamings.query(' `Reference date` == \"Jan-2024\" ')\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n150\nNetflix\nJan-2024\n15.49\n\n\n201\nDisney+\nJan-2024\n13.99\n\n\n246\nHBO Max\nJan-2024\n15.99\n\n\n358\nParamount+\nJan-2024\n11.99\n\n\n452\nPrime Video\nJan-2024\n11.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n\n\n\n\n# Listando interesses:\nstreamings_de_interesse = ['Paramount+', 'Netflix']\n\n# Realizando a consulta:\nconsulta = preco_streamings.query(' `Streaming service` in @streamings_de_interesse ')\nconsulta\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n354\nParamount+\nSep-2023\n11.99\n\n\n355\nParamount+\nOct-2023\n11.99\n\n\n356\nParamount+\nNov-2023\n11.99\n\n\n357\nParamount+\nDec-2023\n11.99\n\n\n358\nParamount+\nJan-2024\n11.99\n\n\n\n\n263 rows × 3 columns\n\n\n\n\n\n\nVejamos outros tipos de filtros de coluna utilizando o cojunto de dados de vendas:\n\nFilter\n\nO método .filter() é muito útil em algumas situações.\n\nvendas_europa = pd.read_csv('dados/vendas/EuropeSalesRecords.csv')\nvendas_europa\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n634033286\n1/15/2014\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n559183347\n5/21/2014\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n781416594\n12/23/2015\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n1330 rows × 14 columns\n\n\n\n\nLike\n\n\nvendas_europa.filter(like='Order', axis=1)\n\n\n\n\n\n\n\n\nOrder Priority\nOrder Date\nOrder ID\n\n\n\n\n0\nC\n9/12/2011\n478051030\n\n\n1\nM\n10/14/2013\n919133651\n\n\n2\nC\n8/13/2014\n987410676\n\n\n3\nL\n10/31/2010\n672330081\n\n\n4\nL\n9/28/2016\n579463422\n\n\n...\n...\n...\n...\n\n\n1325\nM\n1/14/2014\n634033286\n\n\n1326\nL\n4/14/2014\n559183347\n\n\n1327\nM\n11/9/2015\n781416594\n\n\n1328\nH\n5/9/2012\n713357150\n\n\n1329\nL\n4/22/2014\n906794202\n\n\n\n\n1330 rows × 3 columns\n\n\n\n\nPor tipo de dado\n\n\n# selecionar colunas numéricas:\ncolunas_numericas = vendas_europa.select_dtypes(include=['number'])\ncolunas_numericas\n\n\n\n\n\n\n\n\nOrder ID\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\n478051030\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\n919133651\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\n987410676\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\n672330081\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\n579463422\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\n634033286\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\n559183347\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\n781416594\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\n713357150\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\n906794202\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n1330 rows × 7 columns\n\n\n\n\n# selecionar colunas categóricas:\ncolunas_categoricas = vendas_europa.select_dtypes(include=['object'])\ncolunas_categoricas\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nShip Date\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n9/29/2011\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n11/4/2013\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n9/6/2014\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n11/29/2010\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n11/1/2016\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n1/15/2014\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n5/21/2014\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n12/23/2015\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n6/3/2012\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n5/11/2014\n\n\n\n\n1330 rows × 7 columns\n\n\n\nÉ possível, ainda, filtrar pelo tipo de dado em específico:\n\nprint( vendas_europa.select_dtypes('object').columns.tolist() )\nprint( vendas_europa.select_dtypes('float64').columns.tolist() )\n\n['Region', 'Country', 'Item Type', 'Sales Channel', 'Order Priority', 'Order Date', 'Ship Date']\n['Unit Price', 'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit']"
  },
  {
    "objectID": "sections/slicing_e_filtros.html#selecionar-colunas",
    "href": "sections/slicing_e_filtros.html#selecionar-colunas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Uma maneira simples de selecionar colunas é especificar quais colunas se quer filtrar utilizando colchetes duplos ([['coluna A', 'coluna B', 'coluna N']]).\n\npreco_streamings[['Streaming service', 'Price (USD)']]\n\n\n\n\n\n\n\n\nStreaming service\nPrice (USD)\n\n\n\n\n0\nNetflix\n7.99\n\n\n1\nNetflix\n7.99\n\n\n2\nNetflix\n7.99\n\n\n3\nNetflix\n7.99\n\n\n4\nNetflix\n7.99\n\n\n...\n...\n...\n\n\n499\nApple TV+\n6.99\n\n\n500\nApple TV+\n6.99\n\n\n501\nApple TV+\n6.99\n\n\n502\nApple TV+\n6.99\n\n\n503\nApple TV+\n9.99\n\n\n\n\n504 rows × 2 columns\n\n\n\nInclusive, é possível salvar essa seleção em outro dataframe (ou variável): `\n\nstreaming_e_preco = preco_streamings[['Streaming service', 'Price (USD)']]\nstreaming_e_preco.tail(3)\n\n\n\n\n\n\n\n\nStreaming service\nPrice (USD)\n\n\n\n\n501\nApple TV+\n6.99\n\n\n502\nApple TV+\n6.99\n\n\n503\nApple TV+\n9.99"
  },
  {
    "objectID": "sections/slicing_e_filtros.html#eliminar-colunas",
    "href": "sections/slicing_e_filtros.html#eliminar-colunas",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Vamos supor que eu queria trabalhar apenas com a lista de streamings disponíveis no dataset. Uma maneira de fazer isso é:\n\nListar as duplicatas de Streaming service\nEliminar as demais colunas.\n\nPara isso, podemos usar os métodos .drop_duplicates() e o método .drop() - este último tem como opções indicar o eixo (0: linhas, 1: colunas) e o paramêtro inplace=True, que permite sobreescrever o dataframe.\n\n# Listando os serviços de streaming (sem duplicatas) e as demais colunas:\nstreamings = preco_streamings.drop_duplicates(subset='Streaming service')\n\n# Elimiando as colunas de data e preço:\nstreamings.drop(['Reference date', 'Price (USD)'], axis=1, inplace=True)\nstreamings\n\n\n\n\n\n\n\n\nStreaming service\n\n\n\n\n0\nNetflix\n\n\n151\nDisney+\n\n\n202\nHBO Max\n\n\n247\nParamount+\n\n\n359\nPrime Video\n\n\n453\nApple TV+"
  },
  {
    "objectID": "sections/slicing_e_filtros.html#slicing-com-loc-e-iloc",
    "href": "sections/slicing_e_filtros.html#slicing-com-loc-e-iloc",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Os métodos mencionados no título da seção são muito eficazes e permitem selecionar linhas e também a combinação de linhas e colunas.\n# loc (selecionar linhas)\ndf.loc[i]\n\n# iloc (selecionar linhas e colunas)\ndf.iloc[i,j]\nPara melhor entendimento, vejamos alguns exemploa:\n\nLinha 20 (lembre que os índices começam em 0)\n\n\npreco_streamings.loc[19]\n\nStreaming service     Netflix\nReference date       Feb-2013\nPrice (USD)              7.99\nName: 19, dtype: object\n\n\n\nÍndices 400-405\n\n\n# linha 20 (lembre que os índices começam em 0)\npreco_streamings.loc[400:405]\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n400\nPrime Video\nSep-2019\n8.99\n\n\n401\nPrime Video\nOct-2019\n8.99\n\n\n402\nPrime Video\nNov-2019\n8.99\n\n\n403\nPrime Video\nDec-2019\n8.99\n\n\n404\nPrime Video\nJan-2020\n8.99\n\n\n405\nPrime Video\nFeb-2020\n8.99\n\n\n\n\n\n\n\n\nLinhas e colunas\n\n\n# indices 10:14 (10, n-1) e coluna 3 (preço):\npreco_streamings.iloc[10:16, 2]\n\n10    7.99\n11    7.99\n12    7.99\n13    7.99\n14    7.99\n15    7.99\nName: Price (USD), dtype: float64"
  },
  {
    "objectID": "sections/slicing_e_filtros.html#slicing-lógico-condições",
    "href": "sections/slicing_e_filtros.html#slicing-lógico-condições",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Podemos aplicar condições durante o slicing em um dataframe.\n\n# condição:\ncondicao = preco_streamings['Streaming service'] == 'Prime Video'\n\n# slicing (apenas Prime Video):\npreco_streamings[condicao]\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n359\nPrime Video\nApr-2016\n8.99\n\n\n360\nPrime Video\nMay-2016\n8.99\n\n\n361\nPrime Video\nJun-2016\n8.99\n\n\n362\nPrime Video\nJul-2016\n8.99\n\n\n363\nPrime Video\nAug-2016\n8.99\n\n\n...\n...\n...\n...\n\n\n448\nPrime Video\nSep-2023\n8.99\n\n\n449\nPrime Video\nOct-2023\n8.99\n\n\n450\nPrime Video\nNov-2023\n8.99\n\n\n451\nPrime Video\nDec-2023\n8.99\n\n\n452\nPrime Video\nJan-2024\n11.99\n\n\n\n\n94 rows × 3 columns\n\n\n\nCertamente, isso pode ser realizado em uma única linha de código também:\n\n# slicing (todos os streamings menos Prime Video):\npreco_streamings[preco_streamings['Streaming service'] != 'Prime Video']\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n499\nApple TV+\nSep-2023\n6.99\n\n\n500\nApple TV+\nOct-2023\n6.99\n\n\n501\nApple TV+\nNov-2023\n6.99\n\n\n502\nApple TV+\nDec-2023\n6.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n410 rows × 3 columns\n\n\n\nOutro exemplo seria:\n\n# condição:\ncondicao_A = preco_streamings['Streaming service'] == 'Prime Video' \ncondicao_B = preco_streamings['Streaming service'] == 'Disney+'\n\n# slicing (streamings: Prime Video ou Disney+ ):\npreco_streamings[condicao_A | condicao_B]\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n151\nDisney+\nNov-2019\n6.99\n\n\n152\nDisney+\nDec-2019\n6.99\n\n\n153\nDisney+\nJan-2020\n6.99\n\n\n154\nDisney+\nFeb-2020\n6.99\n\n\n155\nDisney+\nMar-2020\n6.99\n\n\n...\n...\n...\n...\n\n\n448\nPrime Video\nSep-2023\n8.99\n\n\n449\nPrime Video\nOct-2023\n8.99\n\n\n450\nPrime Video\nNov-2023\n8.99\n\n\n451\nPrime Video\nDec-2023\n8.99\n\n\n452\nPrime Video\nJan-2024\n11.99\n\n\n\n\n145 rows × 3 columns"
  },
  {
    "objectID": "sections/slicing_e_filtros.html#consultas-sql-com-o-query",
    "href": "sections/slicing_e_filtros.html#consultas-sql-com-o-query",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Podemos utilizar de expressões muito similares a linguagem SQL.\n#query\ndf.query(&lt;expressão&gt;)\nVejamos alguns exemplos que ilustram as possibilidades desse método.\n\npreco_streamings.query(' `Price (USD)` &gt;= 7.99 & `Price (USD)` &lt; 11.99')\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n448\nPrime Video\nSep-2023\n8.99\n\n\n449\nPrime Video\nOct-2023\n8.99\n\n\n450\nPrime Video\nNov-2023\n8.99\n\n\n451\nPrime Video\nDec-2023\n8.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n376 rows × 3 columns\n\n\n\n\npreco_streamings.query(' `Reference date` == \"Jan-2024\" ')\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n150\nNetflix\nJan-2024\n15.49\n\n\n201\nDisney+\nJan-2024\n13.99\n\n\n246\nHBO Max\nJan-2024\n15.99\n\n\n358\nParamount+\nJan-2024\n11.99\n\n\n452\nPrime Video\nJan-2024\n11.99\n\n\n503\nApple TV+\nJan-2024\n9.99\n\n\n\n\n\n\n\n\n# Listando interesses:\nstreamings_de_interesse = ['Paramount+', 'Netflix']\n\n# Realizando a consulta:\nconsulta = preco_streamings.query(' `Streaming service` in @streamings_de_interesse ')\nconsulta\n\n\n\n\n\n\n\n\nStreaming service\nReference date\nPrice (USD)\n\n\n\n\n0\nNetflix\nJul-2011\n7.99\n\n\n1\nNetflix\nAug-2011\n7.99\n\n\n2\nNetflix\nSep-2011\n7.99\n\n\n3\nNetflix\nOct-2011\n7.99\n\n\n4\nNetflix\nNov-2011\n7.99\n\n\n...\n...\n...\n...\n\n\n354\nParamount+\nSep-2023\n11.99\n\n\n355\nParamount+\nOct-2023\n11.99\n\n\n356\nParamount+\nNov-2023\n11.99\n\n\n357\nParamount+\nDec-2023\n11.99\n\n\n358\nParamount+\nJan-2024\n11.99\n\n\n\n\n263 rows × 3 columns"
  },
  {
    "objectID": "sections/slicing_e_filtros.html#outros-filtros-de-coluna",
    "href": "sections/slicing_e_filtros.html#outros-filtros-de-coluna",
    "title": "Manipulação de Dados com Pandas",
    "section": "",
    "text": "Vejamos outros tipos de filtros de coluna utilizando o cojunto de dados de vendas:\n\nFilter\n\nO método .filter() é muito útil em algumas situações.\n\nvendas_europa = pd.read_csv('dados/vendas/EuropeSalesRecords.csv')\nvendas_europa\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nOrder ID\nShip Date\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n478051030\n9/29/2011\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n919133651\n11/4/2013\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n987410676\n9/6/2014\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n672330081\n11/29/2010\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n579463422\n11/1/2016\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n634033286\n1/15/2014\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n559183347\n5/21/2014\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n781416594\n12/23/2015\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n713357150\n6/3/2012\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n906794202\n5/11/2014\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n1330 rows × 14 columns\n\n\n\n\nLike\n\n\nvendas_europa.filter(like='Order', axis=1)\n\n\n\n\n\n\n\n\nOrder Priority\nOrder Date\nOrder ID\n\n\n\n\n0\nC\n9/12/2011\n478051030\n\n\n1\nM\n10/14/2013\n919133651\n\n\n2\nC\n8/13/2014\n987410676\n\n\n3\nL\n10/31/2010\n672330081\n\n\n4\nL\n9/28/2016\n579463422\n\n\n...\n...\n...\n...\n\n\n1325\nM\n1/14/2014\n634033286\n\n\n1326\nL\n4/14/2014\n559183347\n\n\n1327\nM\n11/9/2015\n781416594\n\n\n1328\nH\n5/9/2012\n713357150\n\n\n1329\nL\n4/22/2014\n906794202\n\n\n\n\n1330 rows × 3 columns\n\n\n\n\nPor tipo de dado\n\n\n# selecionar colunas numéricas:\ncolunas_numericas = vendas_europa.select_dtypes(include=['number'])\ncolunas_numericas\n\n\n\n\n\n\n\n\nOrder ID\nUnits Sold\nUnit Price\nUnit Cost\nTotal Revenue\nTotal Cost\nTotal Profit\n\n\n\n\n0\n478051030\n4778\n47.45\n31.79\n226716.10\n151892.62\n74823.48\n\n\n1\n919133651\n927\n109.28\n35.84\n101302.56\n33223.68\n68078.88\n\n\n2\n987410676\n5616\n205.70\n117.11\n1155211.20\n657689.76\n497521.44\n\n\n3\n672330081\n6266\n651.21\n524.96\n4080481.86\n3289399.36\n791082.50\n\n\n4\n579463422\n4958\n9.33\n6.92\n46258.14\n34309.36\n11948.78\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\n634033286\n3394\n81.73\n56.67\n277391.62\n192337.98\n85053.64\n\n\n1326\n559183347\n3633\n205.70\n117.11\n747308.10\n425460.63\n321847.47\n\n\n1327\n781416594\n7390\n421.89\n364.69\n3117767.10\n2695059.10\n422708.00\n\n\n1328\n713357150\n7088\n109.28\n35.84\n774576.64\n254033.92\n520542.72\n\n\n1329\n906794202\n9410\n109.28\n35.84\n1028324.80\n337254.40\n691070.40\n\n\n\n\n1330 rows × 7 columns\n\n\n\n\n# selecionar colunas categóricas:\ncolunas_categoricas = vendas_europa.select_dtypes(include=['object'])\ncolunas_categoricas\n\n\n\n\n\n\n\n\nRegion\nCountry\nItem Type\nSales Channel\nOrder Priority\nOrder Date\nShip Date\n\n\n\n\n0\nEurope\nCzech Republic\nBeverages\nOffline\nC\n9/12/2011\n9/29/2011\n\n\n1\nEurope\nBosnia and Herzegovina\nClothes\nOnline\nM\n10/14/2013\n11/4/2013\n\n\n2\nEurope\nAustria\nCereal\nOffline\nC\n8/13/2014\n9/6/2014\n\n\n3\nEurope\nBulgaria\nOffice Supplies\nOnline\nL\n10/31/2010\n11/29/2010\n\n\n4\nEurope\nEstonia\nFruits\nOnline\nL\n9/28/2016\n11/1/2016\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1325\nEurope\nNorway\nPersonal Care\nOffline\nM\n1/14/2014\n1/15/2014\n\n\n1326\nEurope\nUkraine\nCereal\nOffline\nL\n4/14/2014\n5/21/2014\n\n\n1327\nEurope\nArmenia\nMeat\nOffline\nM\n11/9/2015\n12/23/2015\n\n\n1328\nEurope\nDenmark\nClothes\nOffline\nH\n5/9/2012\n6/3/2012\n\n\n1329\nEurope\nFinland\nClothes\nOnline\nL\n4/22/2014\n5/11/2014\n\n\n\n\n1330 rows × 7 columns\n\n\n\nÉ possível, ainda, filtrar pelo tipo de dado em específico:\n\nprint( vendas_europa.select_dtypes('object').columns.tolist() )\nprint( vendas_europa.select_dtypes('float64').columns.tolist() )\n\n['Region', 'Country', 'Item Type', 'Sales Channel', 'Order Priority', 'Order Date', 'Ship Date']\n['Unit Price', 'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit']"
  }
]